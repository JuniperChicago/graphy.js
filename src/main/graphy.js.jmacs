#!/usr/bin/env node
@import '../share/channel.jmacs'

const factory = require('@{channel('core.data.factory')}');

const gobble = (s_text, s_indent='') => {
	let m_pad = /^(\s+)/.exec(s_text.replace(/^([ \t]*\n)/, ''));
	if(m_pad) {
		return s_indent+s_text.replace(new RegExp(`\\n${m_pad[1]}`, 'g'), '\n'+s_indent.trim()).trim();
	}
	else {
		return s_indent+s_text.trim();
	}
};

@.{
	let h_content_types = {
		ttl: {},
		trig: {},
		nt: {},
		nq: {},
	};
}

@> content(s_content)

	// @{s_content} package
	const @{s_content} = {
		// read @{s_content} output
		get read() {
			// memoize
			delete @{s_content}.read;
			return @{s_content}.read = require('@{channel(`content.${s_content}.read`)}');  // eslint-disable-line global-require
		},

		// scan @{s_content} output
		get scan() {
			// memoize
			delete @{s_content}.scan;
			return @{s_content}.scan = require('@{channel(`content.${s_content}.scan`)}');  // eslint-disable-line global-require
		},

		// write @{s_content} input
		get write() {
			// memoize
			delete @{s_content}.write;
			return @{s_content}.write = require('@{channel(`content.${s_content}.write`)}');  // eslint-disable-line global-require
		},

		// scribe @{s_content} input
		get scribe() {
			// memoize
			delete @{s_content}.scribe;
			return @{s_content}.scribe = require('@{channel(`content.${s_content}.scribe`)}');  // eslint-disable-line global-require
		},
	};
@;

@*{
	for(let s_content in h_content_types) {
		yield content(s_content);
	}
}


// // SPARQL Results package
// const sparql_results = {
// 	// deserialize sparql_results input
// 	get deserializer() {
// 		// memoize
// 		delete sparql_results.deserializer;
// 		return (sparql_results.deserializer = require('../sparql-results/deserializer.js'));
// 	},
// };


const H_CONTENT_MIMES = {
	'text/turtle': ttl,
	'application/trig': trig,
	'application/n-triples': nt,
	'application/n-quads': nq,
	// 'application/sparql-results+json': sparql_results,
};

const H_CONTENT_TAGS = {
	nt,
	'n-triples': nt,
	ntriples: nt,
	nq,
	'n-quads': nq,
	nquads: nq,
	ttl,
	turtle: ttl,
	trig,
	// 'application/sparql-results+json': sparql_results,
};


@> memoize(s_package)
	@//@object-literal
	get @{s_package.replace(/^.*\.([^.]+)$/, '$1')}() {
		@//@
		// memoize
		delete graphy.@{s_package};
		return (graphy.@{s_package} = require('@{channel(s_package)}'));
	},
@;

@.{
	let h_standalones = {
		bat: {},
		set: {},
		viz: {},
		// store: {},
	};
}

@>> R_TOKENS()
	@//@regex
	[^\0-\x20()<>@,;:\\"\/[\]?.=]+
@;

@//@
const R_CONTENT_TYPE = /^((?:application|text)\/@{R_TOKENS()})(;.+)*$/i;

const graphy = module.exports = Object.assign({

	VERSION: '4.0.0',

	content: Object.assign(function(s_query) {
		if(s_query.toLowerCase() in H_CONTENT_TAGS) {
			return H_CONTENT_TAGS[s_query.toLowerCase()];
		}

		let m_content_type = R_CONTENT_TYPE.exec(s_query);
		if(!m_content_type) throw new Error(`invalid content-type string: "${s_query}"`);
		let [, s_content_type, s_parameters] = m_content_type;
		let s_content_type_normal = s_content_type.toLowerCase();

		if(s_content_type_normal in H_CONTENT_MIMES) {
			return H_CONTENT_MIMES[s_content_type_normal];
		}
		else {
			throw new Error(`no content handlers matched query for "${s_content_type_normal}"`);
		}
	}, {
		@*{
			for(let s_content in h_content_types) {
				yield /* syntax: js.object-literal */ `${s_content},\n`;
			}
		}
	}),

	core: {
		data: {
			@{memoize('core.data.factory')}
		},
	},

	get 'core.data.factory'() {
		delete graphy['core.data.factory'];
		return (graphy['core.data.factory'] = require('@{channel('core.data.factory')}'));
	},

	get 'util.dataset.tree'() {
		delete graphy['util.dataset.tree'];
		return (graphy['util.dataset.tree'] = require('@{channel('util.dataset.tree')}'));
	},

	util: {
		dataset: {
			@{memoize('util.dataset.tree')}
		},
	},

	@*{
		for(let s_content in h_content_types) {
			yield /* syntax: js.object-literal */ `
				get 'content.${s_content}.read' () {
					// memoize
					delete graphy['content.${s_content}.read'];
					return graphy['content.${s_content}.read'] = require('${channel(`content.${s_content}.read`)}');  // eslint-disable-line global-require
				},
			`;

			yield /* syntax: js.object-literal */ `
				get 'content.${s_content}.write' () {
					// memoize
					delete graphy['content.${s_content}.write'];
					return graphy['content.${s_content}.write'] = require('${channel(`content.${s_content}.write`)}');  // eslint-disable-line global-require
				},
			`;

			yield /* syntax: js.object-literal */ `
				get 'content.${s_content}.scribe' () {
					// memoize
					delete graphy['content.${s_content}.scribe'];
					return graphy['content.${s_content}.scribe'] = require('${channel(`content.${s_content}.scribe`)}');  // eslint-disable-line global-require
				},
			`;
		}
	}


@//@object-literal

}, factory);

@//@

// export graphy to window object if in main thread of browser
if('undefined' !== typeof window) window.graphy = graphy;

// cli
if(module === require.main) {
	const fs =require('fs');
	const path = require('path');
	const mk_yargs = require('yargs/yargs');
	const stream = require('@{channel('core.iso.stream')}');

	const parse_filter = require('./quad-expression.js').parse;
	const expression_handler = require('./expression-handler.js');

	const F_ADAPT_STREAM = function(ds_out) {
		let ds_dst = ds_out;

		// non-object mode
		if(!ds_dst._writableState.objectMode) {
			// transform to JSON
			ds_out = stream.quads_to_json();
		}
		// yes object mode and graphy writable
		else if(ds_out.isGraphyWritable) {
			// transform to writable data events
			ds_out = stream.quads_to_writable();
		}
		// forward as-is to super
		else {
			return this.constructor.prototype.pipe.call(this, ds_dst);
		}

		// forward output to super
		this.constructor.prototype.pipe.call(this, ds_out);

		// pipe output to destination
		return ds_out.pipe(ds_dst);
	};

	const bypass = a_inputs => a_inputs.map((ds_input) => {
		// intercept pipe
		ds_input.pipe = F_ADAPT_STREAM;

		return ds_input;
	});

	const map_streams = (a_inputs, f_map) => a_inputs.map((ds_input) => {
		let ds_output = f_map(ds_input);

		// intercept pipe
		ds_output.pipe = F_ADAPT_STREAM;

		// pipe input to step and return step
		return ds_input.pipe(ds_output);
	});

	const warp_term = (z_term, h_prefixes) => {
		// c1 string
		if('string' === typeof z_term) {
			return factory.c1(z_term, h_prefixes);
		}
		// normalize term
		else {
			return factory.fromTerm(z_term);
		}
	};

	const interpret_item = (z_item, h_prefixes, ds_transform, fke_transform) => {
		// array
		if(Array.isArray(z_item)) {
			// zero-length, skip
			if(!z_item.length) return fke_transform();

			// first object is also array
			if(Array.isArray(z_item[0])) {
				let nl_subs = z_item.length;

				let c_resolves = 0;

				for(let z_sub of z_item) {
					interpret_item(z_sub, h_prefixes, ds_transform, () => {  // eslint-disable-line no-loop-func
						if(++c_resolves === nl_subs) {
							fke_transform();
						}
					});
				}

				// do not consume transform synchronously
				return;
			}
			// triple/quad
			else if(3 === z_item.length || 4 === z_item.length) {
				let a_terms = z_item.map(z => warp_term(z, h_prefixes));

				ds_transform.push(factory.quad(...a_terms));
			}
		}
		// string (trig)
		else if('string' === typeof z_item) {
			trig.read({
				input: {
					string: z_item,

					error(e_read) {
						warn(`The 'transform' command threw an Error while trying to read the returned TriG string: '${z_item}'\n\nThe reader reported: ${e_read.stack}`);

						// done
						fke_transform();
					},
				},

				data(g_quad_read) {
					ds_transform.push(g_quad_read);
				},

				eof() {
					// done
					fke_transform();
				},
			});

			// do not consume transform synchronously
			return;
		}
		// quad
		else if(z_item.subject && z_item.predicate && z_item.object) {
			ds_transform.push(factory.fromQuad(z_item));
		}
		// iterable
		else if(z_item[Symbol.iterator]) {
			for(let g_quad_it of z_item) {
				ds_transform.push(g_quad_it);
			}
		}
		// other
		else {
			exit(`The callback function supplied to the 'transform' command returned an invalid quad value: '${z_item}'`);
		}

		// done
		fke_transform();
	};

	class answer_source extends require('stream').Readable {
		constructor(w_datum) {
			super({
				objectMode: true,
			});

			this.datum = w_datum;
		}

		// intercept pipe
		pipe(ds_dst) {
			// string out
			if(!ds_dst._writableState.objectMode) {
				// change read mode; push as JSON
				this._read = () => {
					this.push(JSON.stringify(this.datum)+'\n', 'utf8');
					this.push(null);
				};
			}

			// forward to super
			return super.pipe(ds_dst);
		}

		// push object
		_read() {
			this.push(this.datum);
			this.push(this.null);
		}
	}

	const warn = (s_message) => {
		console.warn((new Error(s_message)).stack
			.replace(/\n\s+at [^\n]*\n/, '\n')
			.replace(/^Error:/, 'Warning:'));
	};

	const exit = (s_exit) => {
		console.error(s_exit);
		process.exit(1);
	};

	const command = (a_args, s_command, a_decsribes, h_options) => mk_yargs()
		.strict()
		.usage(`Usage: $0 ${s_command} [OPTIONS] [ / COMMAND]${a_decsribes.length? `\n\n${a_decsribes.join('\n\n')}`: ''}`)
		.options(h_options)
		.help()
		.version(false)
		.parse(a_args);

	const S_TRANSFORM_TYPE_NNSQ = 'Transform Type: N-to-N (map);  (...Strings) --> [...Quads]';
	const S_TRANSFORM_TYPE_NNQS = 'Transform Type: N-to-N (map);  (...Quads) --> [...Strings]';
	const S_TRANSFORM_TYPE_NNQQ = 'Transform Type: N-to-N (map);  (...Quads) --> [...Quads]';
	const S_TRANSFORM_TYPE_21QQ = 'Transform Type: 2-to-1 (join);  (Quads, Quads) --> [Quads]';
	const S_TRANSFORM_TYPE_N1QQ = 'Transform Type: N-to-1 (reduce);  (...Quads) -->  [Quads]';
	const S_TRANSFORM_TYPE_21QR = 'Transform Type: 2-to-1 (join);  (Quads, Quads) --> [ResultValues]';

	const S_CATEGORY_IO = 'Input/Output Commands:'
	const S_CATEGORY_DATA = 'Quad-Level Commands:';
	const S_CATEGORY_STREAM = 'Stream Control Commands:';
	const S_CATEGORY_SET = 'Dataset Commands:';

	const S_WARN_JAVASCRIPT = `WARNING: the '-j' / '--js' / '--javascript' option evals the given code. Do not allow user input into this option as it will grant them arbitrary code execution with whatever privileges the process is running with.`;

	const content_type_flags = f_verb => ({
		nt: {
			type: 'boolean',
			alias: ['ntriples', 'n-triples'],
			conflicts: ['ttl', 'nq', 'trig'],
			describe: f_verb('N-Triples'),
		},

		nq: {
			type: 'boolean',
			alias: ['nquads', 'n-quads'],
			conflicts: ['nt', 'ttl', 'trig'],
			describe: f_verb('N-Quads'),
		},

		ttl: {
			type: 'boolean',
			alias: ['turtle'],
			conflicts: ['nt', 'nq', 'trig'],
			describe: f_verb(' Turtle'),
		},

		trig: {
			type: 'boolean',
			conflicts: ['nt', 'nq', 'ttl'],
			describe: f_verb('TriG'),
		},
	});

	// commands
	let h_commands = {  // eslint-disable-next-line quote-props
/*
 ------ Input/Output --------
 */

		read: {
			type: S_TRANSFORM_TYPE_NNSQ,
			category: S_CATEGORY_IO,
			overview: 'Deserialize RDF content',
			description: [
				'Read RDF content (i.e., deserialize it) from 1 or more inputs',
			],
			options: {
				r: {
					type: 'boolean',
					alias: ['relax'],
					default: undefined,  // eslint-disable-line no-undefined
					describe: 'relax validation of tokens within the RDF document',
				},
				b: {
					type: 'string',
					alias: ['base', 'base-uri', 'base-iri'],
					describe: 'set a base URI on the document',
				},
				c: {
					type: 'string',
					alias: ['content-type'],
					default: 'trig',
					describe: 'either an RDF Content-Type or format selector',
					example: [
						`read -c nt`,
						`read -c n-triples`,
						`read -c 'application/n-triples'`,
						`read -c ttl`,
						`read -c turtle`,
						`read -c 'text/turtle'`,
					].join('\n'),
				},

				...content_type_flags(s => `read from ${s}`),
			},

			command(g_argv, a_inputs, fe_command) {
				// select reader
				let f_reader = graphy.content(g_argv['content-type']).read;

				let gc_read = {
					relax: g_argv.relax || false,
				};

				// 'base-uri' => 'baseUri'
				if(g_argv['base-uri']) {
					gc_read.baseUri = g_argv['base-uri'];
				}

				return map_streams(a_inputs, () => f_reader({
					...gc_read,

					error: e => fe_command(e),
				}));
			},
		},

		scribe: {
			type: S_TRANSFORM_TYPE_NNSQ,
			category: S_CATEGORY_IO,
			overview: 'Serialize RDF content fast',
			description: [
				'Scribe RDF content (i.e., serialize it) fast (and possibly ugly) using the given content-type.',
			],
			options: (_f_scriber=null) => ({
				...(_f_scriber? {} :{
					c: {
						type: 'string',
						alias: ['content-type'],
						default: 'trig',
						describe: 'either an RDF Content-Type or format selector',
						example: [
							`scribe -c nt`,
							`scribe -c n-triples`,
							`scribe -c 'application/n-triples'`,
							`scribe -c ttl`,
							`scribe -c turtle`,
							`scribe -c 'text/turtle'`,
						].join('\n'),
					},

					...content_type_flags(s => `scribe to ${s}`),
				}),
			}),

			command(g_argv, a_inputs, fe_command, _f_scriber=null) {
				// select scriber
				let f_scriber = _f_scriber || graphy.content(g_argv['content-type']).scribe;

				// map input(s) to writer(s)
				return a_inputs.map(ds_input => ds_input.pipe(f_scriber({
					error: e => fe_command(e),
				})));
			},
		},

		write: {
			type: S_TRANSFORM_TYPE_NNQS,
			category: S_CATEGORY_IO,
			overview: 'Serialize RDF content in style (pretty-printing)',
			description: [
				'Write RDF content (i.e., serialize it) in style (for pretty-print) using the given content-type.',
			],
			options(_f_writer=null) {
				let s_group_style = 'Style options:';
				let s_group_list = 'List structure options:'

				return {
					i: {
						type: 'string',
						alias: ['indent'],
						// default: '\\t',  // eslint-disable-line no-undefined
						describe: `sets the whitespace string to use for indentation. Writers use '\\t' by default`,
						group: s_group_style,
					},
					g: {
						type: 'string',
						alias: ['graph-keyword'],
						describe: `sets the style to use when serializing the optional 'GRAPH' keyword in TriG. Writers omit this keyword by default.
							Passing 'true' or empty with this flag on is shorthand for the all-caps 'GRAPH' keyword`.replace(/\n\s*/g, ' '),
						group: s_group_style,
					},
					s: {
						type: 'boolean',
						alias: ['simplify-default-graph'],
						default: true,
						describe: 'if enabled, omits serializing the surrounding optional graph block for the default graph in TriG.',
						group: s_group_style,
					},
					f: {
						type: 'string',
						alias: ['first'],
						describe: `c1 string: sets the predicate to use for the 'first' relation when serializing list structures`,
						group: s_group_list,
					},
					r: {
						type: 'string',
						alias: ['rest'],
						describe: `c1 string: sets the predicate to use for the 'rest' relation when serializing list structures`,
						group: s_group_list,
					},
					n: {
						type: 'string',
						alias: ['nil'],
						describe: `c1 string: sets the predicate to use for the 'nil' relation when serializing list structures`,
						group: s_group_list,
					},
					...(_f_writer? {} :{
						c: {
							type: 'string',
							alias: ['content-type'],
							default: 'trig',
							describe: 'either an RDF Content-Type or format selector',
							example: [
								`write -c nt`,
								`write -c n-triples`,
								`write -c 'application/n-triples'`,
								`write -c ttl`,
								`write -c turtle`,
								`write -c 'text/turtle'`,
							].join('\n')
						},

						...content_type_flags(s => `write to ${s}`),
					}),
				};
			},

			command(g_argv, a_inputs, fe_command, _f_writer=null) {
				// select writer
				let f_writer = _f_writer || graphy.content(g_argv['content-type']).write;

				// default write config
				let gc_write = {};

				// extend style options
				let g_style = gc_write.style || {};
				{
					// indent
					if(g_argv.indent) g_style.indent = g_argv.indent;

					// graph keyword
					if(g_argv['graph-keyword']) g_style.graph_keyword = g_argv['graph-keyword'];

					// simplify default graph
					if(g_argv['simplify-default-graph']) g_style.simplify_default_graph = g_argv['simplify-default-graph'];
				}

				// extend list options
				let g_lists = gc_write.lists || {};
				{
					// first
					if(g_argv.first) g_lists.first = g_argv.first;

					// rest
					if(g_argv.rest) g_lists.rest = g_argv.rest;

					// nil
					if(g_argv.nil) g_lists.nil = g_argv.nil;
				}

				// map input(s) to writer(s)
				return a_inputs.map(ds_input => ds_input.pipe(f_writer({
					...gc_write,

					style: g_style,

					lists: g_lists,

					error: e => fe_command(e),
				})));
			},
		},

/*
 ------ Quad-Level --------
 */

		skip: {
			type: S_TRANSFORM_TYPE_NNQQ,
			category: S_CATEGORY_DATA,
			overview: 'Skip over some amount of quads',
			description: 'Skip over some amount of data for each input stream before piping the remainder as usual.',
			options: {
				q: {
					type: 'number',
					alias: ['quads', 't', 'triples'],
					describe: 'skip the given number of quads from the top of a stream',
					conflicts: ['s'],
				},

				s: {
					type: 'number',
					alias: ['subjects'],
					describe: 'skip quads until the given number of distinct subjects have been encountered from the top of a stream',
					conflicts: ['q'],
				},
			},

			command(g_argv, a_inputs, fe_command) {
				// count subjects
				if(g_argv.subjects) {
					let n_subjects = g_argv.subjects || 1;

					return map_streams(a_inputs, (ds_input) => {
						let c_subjects = 0;
						let kt_prev = null;

						return new stream.Transform.QuadsToOther({
							error: e => fe_command(e),

							transform(g_quad, s_encoding, fke_transform) {
								// reached length
								if(!g_quad.subject.equals(kt_prev) && ++c_subjects > n_subjects) {
									// start pushing
									this.push(g_quad);
								}

								// save subject
								kt_prev = g_quad.subject;

								// done
								fke_transform();
							},
						});
					});
				}
				// count quads
				else {
					let n_quads = g_argv.quads || 1;

					return map_streams(a_inputs, (ds_input) => {
						let c_quads = 0;

						return new stream.Transform.QuadsToOther({
							error: e => fe_command(e),

							transform(g_quad, s_encoding, fke_transform) {
								// reached length
								if(++c_quads > n_quads) {
									// start pushing
									this.push(g_quad);
								}

								// done
								fke_transform();
							},
						});
					});
				}
			},
		},

		head: {
			type: S_TRANSFORM_TYPE_NNQQ,
			category: S_CATEGORY_DATA,
			overview: 'Limit number of quads from top',
			description: [
				'Limit the number of quads that pass through by counting from the top of the stream.',
			],
			options: {
				q: {
					type: 'number',
					alias: ['quads', 't', 'triples'],
					describe: 'emit only the given number of quads from the top of a stream',
					conflicts: ['s'],
				},

				s: {
					type: 'number',
					alias: ['subjects'],
					describe: 'emit quads until the given number of distinct subjects have been encountered from the top of a stream',
					conflicts: ['q'],
				},
			},

			command(g_argv, a_inputs, fe_command) {
				// count subjects
				if(g_argv.subjects) {
					let n_subjects = g_argv.subjects || 1;

					return map_streams(a_inputs, (ds_input) => {
						let c_subjects = 0;
						let kt_prev = null;

						return new stream.Transform.QuadsToOther({
							error: e => fe_command(e),

							transform(g_quad, s_encoding, fke_transform) {
								// under limit
								if(g_quad.subject.equals(kt_prev) || ++c_subjects <= n_subjects) {
									this.push(g_quad);
								}
								// hit limit
								else {
									// push eof
									this.push(null);

									// destroy source
									ds_input.destroy();
								}

								// save subject
								kt_prev = g_quad.subject;

								// done
								fke_transform();
							},
						});
					});
				}
				// count quads
				else {
					let n_quads = g_argv.quads || 1;

					return map_streams(a_inputs, (ds_input) => {
						let c_quads = 0;

						return new stream.Transform.QuadsToOther({
							error: e => fe_command(e),

							transform(g_quad, s_encoding, fke_transform) {
								// under limit
								if(++c_quads <= n_quads) {
									this.push(g_quad);
								}
								// hit limit
								else {
									// push eof
									this.push(null);

									// destroy source
									ds_input.destroy();
								}

								// done
								fke_transform();
							},
						});
					});
				}
			},
		},

		tail: {
			type: S_TRANSFORM_TYPE_NNQQ,
			category: S_CATEGORY_DATA,
			overview: 'Limit number of quads from bottom',
			description: [
				'Limit the number of quads that pass through by counting from the bottom of the stream.',
				'WARNING: quads must be buffered in memory until the end of the stream is reached. Specifying a large number of quads or subjects might therefore incur lots of memory.',
			],
			options: {
				q: {
					type: 'number',
					alias: ['quads', 't', 'triples'],
					describe: 'emit only the given number of quads from the bottom of a stream',
					conflicts: ['s'],
				},

				s: {
					type: 'number',
					alias: ['subjects'],
					describe: 'emit quads contained by the given number of distinct subjects from the bottom of a stream',
					conflicts: ['q'],
				},
			},

			command(g_argv, a_inputs, fe_command) {
				// count subjects
				if(g_argv.subjects) {
					let n_subjects = g_argv.subjects || 1;

					return map_streams(a_inputs, (ds_input) => {
						let c_subjects = 0;
						let kt_prev = null;
						let a_batch = null;
						let a_fifo = [];

						return new stream.Transform.QuadsToOther({
							error: e => fe_command(e),

							transform(g_quad, s_encoding, fke_transform) {
								// different subject
								if(!g_quad.subject.equals(kt_prev)) {
									// reset batch
									a_batch = [];

									// push batch to fifo
									a_fifo.push(a_batch);
									
									// hit limit
									if(++c_subjects > n_subjects) {
										a_fifo.shift();
									}
								}

								// save subject
								kt_prev = g_quad.subject;

								// add quad to batch
								a_batch.push(g_quad);

								// done
								fke_transform();
							},

							flush(fk_flush) {
								// push queue
								for(let a_quads of a_fifo) {
									for(let g_quad of a_quads) {
										this.push(g_quad);
									}
								}

								// free to GC
								a_fifo.length = 0;
								a_batch.length = 0;

								// done
								fk_flush();
							}
						});
					});
				}
				// count quads
				else {
					let n_quads = g_argv.quads || 1;

					return map_streams(a_inputs, (ds_input) => {
						let c_quads = 0;
						let a_fifo = [];

						return new stream.Transform.QuadsToOther({
							error: e => fe_command(e),

							transform(g_quad, s_encoding, fke_transform) {
								// under limit
								if(++c_quads <= n_quads) {
									a_fifo.push(g_quad);
								}
								// hit limit
								else {
									// shift off bottom
									a_fifo.shift();

									// push to top
									a_fifo.push(g_quad);
								}

								// done
								fke_transform();
							},

							flush(fk_flush) {
								// push queue
								for(let g_quad of a_fifo) {
									this.push(g_quad);
								}

								// free to GC
								a_fifo.length = 0;

								// done
								fk_flush();
							},
						});
					});
				}
			},
		},

		filter: {
			type: S_TRANSFORM_TYPE_N1QQ,
			category: S_CATEGORY_DATA,
			overview: 'Filter quads via expression',
			description: [
				'Filter quads by using either a Quad Filter Expression or a bit of JavaScript.',
				'For documentation on the Quad Filter Expression syntax, see:  https://graphy.link/quad-filter-expression',
				S_WARN_JAVASCRIPT,
			],
			options: {
				x: {
					type: 'string',
					alias: ['expression'],
					describe: 'filter quads using the given quad filter expression',
					conflicts: ['j'],
					example: [
						`filter -x '; a; dbo:Plant'`,
						`filter -x 'dbr:Banana;; !{literal}'`,
					].join('\n'),
				},

				j: {
					type: 'string',
					alias: ['js', 'javascript'],
					describe: 'filter quads using the given JavaScript expression which will be evaluated as a callback function passed the quad and current prefix map as arguments',
					conflicts: ['x'],
					example: [
						`filter -j 'g => g.object.number > 10e3'`,
						`filter -j 'g => g.object.value.startsWith(g.subject.value)'`,
						`filter -j '(g, h) => g.subject.concise(h).startsWith("db")'`,
					].join('\n'),
				},

				v: {
					type: 'boolean',
					alias: ['verbose'],
					describe: 'prints the compiled quad filter expression to stderr',
				},
			},

			command(g_argv, a_inputs, fe_command) {
				// quad filter expression
				if(g_argv.expression) {
					let g_parse = parse_filter(g_argv.expression);

					let sj_eval = expression_handler.prepare(g_parse);

					if(g_argv.verbose) {
						console.warn(`The compiled quad filter expression from 'transform' command: () => {\n${sj_eval.replace(/^|\n/g, '\n\t')}\n}\n`);
					}

					let f_filter = new Function('factory', 'stream', sj_eval);  // eslint-disable-line no-new-func

					return map_streams(a_inputs, () => f_filter(factory, stream));
				}
				// javascript expression
				else if(g_argv.javascript) {
					let f_build = new Function('factory', /* syntax: js */ `return (${g_argv.javascript}) || null;`);  // eslint-disable-line no-new-func

					let f_filter = f_build(factory);

					// filter exists
					if(f_filter) {
						// invalid type
						if('function' !== typeof f_filter) {
							exit(`The 'filter' command expects -j/--javascript expression to evaluate to a function, instead found '${typeof f_filter}'`);
						}

						return map_streams(a_inputs, () => {
							let h_prefixes = {};

							return new stream.Transform.QuadsToOther({
								error: e => fe_command(e),

								prefix(si_prefix, p_iri) {
									h_prefixes[si_prefix] = p_iri;
								},

								transform(g_quad, s_encoding, fke_transform) {
									if(f_filter(g_quad, h_prefixes)) {
										return fke_transform(null, g_quad);
									}

									fke_transform();
								},
							});
						});
					}
				}

				// neither used (bypass filter)
				warn(`The 'filter' command was not used and is being ignored.`);
				return bypass(a_inputs);
			},
		},

		// transform
		transform: {
			type: S_TRANSFORM_TYPE_N1QQ,
			category: S_CATEGORY_DATA,
			overview: 'Apply a custom transform function to each quad in the stream(s)',
			description: [
				'$1',
				S_WARN_JAVASCRIPT,
			],
			options: {
				j: {
					type: 'string',
					alias: ['js', 'javascript'],
					describe: 'transform quads using the given JavaScript expression which will be evaluated as a callback function passed the quad and current prefix map as arguments',
					demandOption: true,
					example: [
						`transform -j 'g => [g.object, g.predicate, g.subject]'`,
						`transform -j 'g => ({
							[factory.blankNode()]: {
								a: 'rdf:Statement',
								'rdf:subject': g.subject,
								'rdf:predicate': g.predicate,
								'rdf:object': g.object,
							},
						})'`,
					].join('\n'),
				},
			},

			command(g_argv, a_inputs, fe_command) {
				// javascript expression
				if(g_argv.javascript) {
					let f_build = new Function('factory', 'c3', 'c4', /* syntax: js */ `return (${g_argv.javascript}) || null;`);  // eslint-disable-line no-new-func

					let f_transform = f_build(factory, factory.c3, factory.c4);

					// transform exists
					if(f_transform) {
						// invalid type
						if('function' !== typeof f_transform) {
							exit(`The 'filter' command expects -j/--javascript expression to evaluate to a function, instead found '${typeof f_filter}'`);
						}

						return map_streams(a_inputs, () => {
							let h_prefixes = {};

							return new stream.Transform.QuadsToOther({
								error: e => fe_command(e),

								prefix(si_prefix, p_iri) {
									h_prefixes[si_prefix] = p_iri;
								},

								transform(g_quad, s_encoding, fke_transform) {
									// alias quad property access
									g_quad.s = g_quad.subject;
									g_quad.p = g_quad.predicate;
									g_quad.o = g_quad.object;
									g_quad.g = g_quad.graph;

									// try to apply transform callback
									let z_item;
									try {
										z_item = f_transform(g_quad, h_prefixes);
									}
									catch(e_transform) {
										warn(`The 'transform' command threw an Error while applying the given callback function:\n${e_transform.stack}`);
										return fke_transform();
									}

									// item was returned
									if(z_item) {
										return interpret_item(z_item, h_prefixes, this, fke_transform);
									}

									// done
									fke_transform();
								},
							});
						});
					}
				}

				// nothing used (bypass filter)
				warn(`The 'transform' command was not used and is being ignored.`);
				return bypass(a_inputs);
			},
		},

/*
 ------ Stream Control --------
 */

		concat: {
			type: S_TRANSFORM_TYPE_N1QQ,
			category: S_CATEGORY_STREAM,
			overview: 'Join stream data in order via concatentation',
			description: [
				'Concatenate quads from all input streams in order.',
			],
			options: {},

			command(g_argv, a_inputs, fe_command) {
				let nl_inputs = a_inputs.length;

				// single input, bypass passthrough
				if(1 === nl_inputs) return a_inputs;

				// input index
				let i_input = 0;

				// single output stream
				let ds_out = new stream.PassThrough();

				// stream consumer
				let f_next = () => {
					// done consuming inputs; end output stream
					if(i_input >= nl_inputs) return ds_out.end();

					// next input
					let ds_input = a_inputs[i_input++];

					// once it ends; consume next input
					ds_input.on('end', f_next);

					// catch stream errors
					ds_input.on('error', fe_command);

					// pipe to passthrough
					ds_input.pipe(ds_out, {end:false});
				};

				// start concatenating
				f_next();

				// return stream
				return [ds_out];

				// return [new stream.Readable({
				// 	objectMode: true,

				// 	read() {
				// 		// while there are inputs
				// 		for(; i_input<nl_inputs; i_input++) {
				// 			// ref input
				// 			let ds_input = a_inputs[i_input];

				// 			// read chunk from input and push to output
				// 			let w_chunk;
				// 			while((w_chunk = ds_input.read()) && this.push(w_chunk)) {
				// 				; // eslint-disable-line no-empty
				// 			}

				// 			// input not fully consumed; try again next read
				// 			if(!w_chunk.readableEnded) break;
				// 		}
				// 	},
				// })];
			},
		},

		merge: {
			type: S_TRANSFORM_TYPE_N1QQ,
			category: S_CATEGORY_STREAM,
			overview: `Join stream data on a 'first come, first serve' basis`,
			description: [
				'Merge quads from all input streams without order.',
			],
			options: {},

			command(g_argv, a_inputs, fe_command) {
				let nl_inputs = a_inputs.length;

				// single input, bypass passthrough
				if(1 === nl_inputs) return a_inputs;

				// input index
				let i_input = 0;

				// single output stream
				let ds_out = new stream.PassThrough();

				// stream consumer
				let f_next = () => {
					// done consuming inputs; end output stream
					if(i_input >= nl_inputs) return ds_out.end();

					// next input
					let ds_input = a_inputs[i_input++];

					// once it ends; consume next input
					ds_input.on('end', f_next);

					// catch stream errors
					ds_input.on('error', fe_command);

					// pipe to passthrough
					ds_input.pipe(ds_out, {end:false});
				};

				// start concatenating
				f_next();

				// return stream
				return [ds_out];
			},
		},

/*
 ------ Dataset --------
 */

		union: {
			type: S_TRANSFORM_TYPE_N1QQ,
			category: S_CATEGORY_SET,
			overview: 'Compute the set union of 1 or more inputs',
			description: [
				'$1.',
			],
			options: {},

			command(g_argv, a_inputs, fe_command) {
				return map_streams(a_inputs, () => new stream.Transform.QuadsToOther({
					error: e => fe_command(e),
				}));
			},
		},


		// boilerplate: {
		// 	type: S_TRANSFORM_TYPE_N1QQ,
		// 	overview: '',
		// 	description: [
		// 		'Some decsription',
		// 	],
		// 	options: {},

		// 	command(g_argv, a_inputs, fe_command) {
		// 		return map_streams(a_inputs, () => new Transform({
		// 			error: e => fe_command(e),
		// 		}));
		// 	},
		// },


		// 'util.dataset.tree': async(g_argv, a_inputs, fe_command) => {
		// 	const dataset_tree = graphy.util.dataset.tree;

		// 	let s_group_multi_input = 'Transform 1 or more inputs to 1 output:';
		// 	let s_group_dual_input = 'Transform exactly 2 inputs into 1 output:';
		// 	let s_group_boolean = 'Test exactly 2 inputs to get `true` or `false`:';

		// 	let h_operations = {
		// 		u: {
		// 			type: 'boolean',
		// 			alias: ['union'],
		// 			group: s_group_multi_input,
		// 			describe: 'perform the union of 1 or more inputs',
		// 		},
		// 		i: {
		// 			type: 'boolean',
		// 			alias: ['intersect', 'intersection'],
		// 			group: s_group_multi_input,
		// 			describe: 'perform the intersection of 1 or more inputs',
		// 		},
		// 		d: {
		// 			type: 'boolean',
		// 			alias: ['diff', 'difference'],
		// 			group: s_group_dual_input,
		// 			describe: 'perform a difference between two inputs',
		// 		},
		// 		m: {
		// 			type: 'boolean',
		// 			alias: ['minus', 'subtract', 'subtraction'],
		// 			group: s_group_dual_input,
		// 			describe: 'perform a subtraction by removing input-B from input-A',
		// 		},
		// 		c: {
		// 			type: 'boolean',
		// 			alias: ['contains'],
		// 			group: s_group_boolean,
		// 			describe: 'test if input-A completely contains input-B, i.e., if B is a subset of A',
		// 		},
		// 		j: {
		// 			type: 'boolean',
		// 			alias: ['disjoint'],
		// 			group: s_group_boolean,
		// 			describe: 'test if input-A is disjoint with input-B',
		// 		},
		// 		e: {
		// 			type: 'boolean',
		// 			alias: ['equals'],
		// 			group: s_group_boolean,
		// 			describe: 'test if input-A is exactly equal to input-B (you can test for isomorphism by piping thru --canonicalize first)',
		// 		},
		// 	};

		// 	let a_operation_keys = Object.keys(h_operations);
		// 	for(let s_operation of a_operation_keys) {
		// 		h_operations[s_operation].conflicts = a_operation_keys.filter(s => s_operation !== s);
		// 	}

		// 	Object.assign(h_operations, {
		// 		z: {
		// 			type: 'boolean',
		// 			alias: ['canonicalize'],
		// 			group: s_group_multi_input,
		// 			describe: 'canonicalize 1 or more inputs',
		// 		},
		// 	});

		// 	// canonicalize flag
		// 	let b_canonicalize = g_argv.canonicalize;

		// 	// ref inputs; cache length
		// 	let a_inputs = g_context.inputs;
		// 	let n_inputs = a_inputs.length;

		// 	// multi-input stream-output operation
		// 	if(g_argv.union || g_argv.intersection) {
		// 		let s_operation = g_argv.union
		// 			? 'union'
		// 			: 'intersection';

		// 		// // less than 2 inputs; no-op
		// 		// if(n_inputs < 2) return a_inputs;

		// 		// create trees
		// 		let a_trees = a_inputs.map(() => dataset_tree());

		// 		// initial tree
		// 		let k_tree_out = a_trees[0];

		// 		// pairwise readiness
		// 		for(let i_input=0; i_input<n_inputs; i_input++) {
		// 			let k_tree_b = a_trees[i_input];

		// 			// pipe input stream to tree b
		// 			a_inputs[i_input].pipe(k_tree_b);

		// 			// wait for input stream to finish writing to b
		// 			await k_tree_b.until('finish');

		// 			// canonicalize
		// 			if(b_canonicalize) {
		// 				k_tree_b = a_trees[i_input] = k_tree_b.canonicalize();

		// 				// update out ref
		// 				if(!i_input) k_tree_out = k_tree_b;
		// 			}

		// 			// non-first input
		// 			if(i_input) {
		// 				// perform pairwise operation
		// 				k_tree_out = k_tree_out[s_operation](k_tree_b);
		// 			}
		// 		}

		// 		// return readable tree
		// 		return [k_tree_out];
		// 	}
		// 	// dual-input stream-output operation
		// 	else if(g_argv.difference || g_argv.subtraction) {
		// 		let s_operation =  g_argv.difference
		// 			? 'difference'
		// 			: 'minus';

		// 		// not two inputs
		// 		if(2 !== n_inputs) {
		// 			exit(`operation '${s_operation}' expects two inputs but found ${n_inputs}`);
		// 		}

		// 		// async
		// 		return new Promise((fk_resolve) => {
		// 			let operate = () => [k_tree_a[s_operation](k_tree_b)];

		// 			// wait for a
		// 			let k_tree_a = dataset_tree();
		// 			let b_finished_a = false;
		// 			k_tree_a.on('finish', () => {
		// 				// canonicalize
		// 				if(b_canonicalize) k_tree_a = k_tree_a.canonicalize();

		// 				// a is finished now
		// 				b_finished_a = true;

		// 				// b is already finished
		// 				if(b_finished_b) fk_resolve(operate());
		// 			});

		// 			// wait for b
		// 			let k_tree_b = dataset_tree();
		// 			let b_finished_b = false;
		// 			k_tree_b.on('finish', () => {
		// 				// canonicalize
		// 				if(b_canonicalize) k_tree_b = k_tree_b.canonicalize();

		// 				// b is finished now
		// 				b_finished_b = true;

		// 				// a is already finished
		// 				if(b_finished_a) fk_resolve(operate());
		// 			});

		// 			// ref both input streams
		// 			let [ds_input_a, ds_input_b] = a_inputs;

		// 			// pipe each to its tree
		// 			ds_input_a.pipe(k_tree_a);
		// 			ds_input_b.pipe(k_tree_b);
		// 		});
		// 	}
		// 	// boolean
		// 	else if(g_argv.contains || g_argv.disjoint || g_argv.equals) {
		// 		let s_operation =  g_argv.contains
		// 			? 'contains'
		// 			: (g_argv.disjoint
		// 				? 'disjoint'
		// 				: 'equals');

		// 		// not two inputs
		// 		if(2 !== n_inputs) {
		// 			exit(`boolean operation '${s_operation}' expects two inputs but found ${n_inputs}`);
		// 		}

		// 		// async
		// 		return new Promise((fk_resolve) => {
		// 			let operate = () => [new answer_source(k_tree_a[s_operation](k_tree_b))];

		// 			// wait for a
		// 			let k_tree_a = dataset_tree();
		// 			let b_finished_a = false;
		// 			k_tree_a.on('finish', () => {
		// 				// canonicalize
		// 				if(b_canonicalize) k_tree_a = k_tree_a.canonicalize();

		// 				// a is finished now
		// 				b_finished_a = true;

		// 				// b is already finished
		// 				if(b_finished_b) fk_resolve(operate());
		// 			});

		// 			// wait for b
		// 			let k_tree_b = dataset_tree();
		// 			let b_finished_b = false;
		// 			k_tree_b.on('finish', () => {
		// 				// canonicalize
		// 				if(b_canonicalize) k_tree_b = k_tree_b.canonicalize();

		// 				// b is finished now
		// 				b_finished_b = true;

		// 				// a is already finished
		// 				if(b_finished_a) fk_resolve(operate());
		// 			});

		// 			// ref both input streams
		// 			let [ds_input_a, ds_input_b] = a_inputs;

		// 			// pipe each to its tree
		// 			ds_input_a.pipe(k_tree_a);
		// 			ds_input_b.pipe(k_tree_b);
		// 		});
		// 	}
		// 	// map; n-to-n
		// 	else {
		// 		return a_inputs.map(ds_input => ds_input.pipe(dataset_tree({
		// 			canonicalize: g_argv.canonicalize,
		// 		})));
		// 	}
		// },
	};


	let n_width_column = Object.keys(h_commands)
		.reduce((n, s) => Math.max(n, s.length), 0);

	// group command by category
	let h_categories = {};
	for(let [si_command, g_command] of Object.entries(h_commands)) {
		let s_category = g_command.category;

		let g_category = (h_categories[s_category] = h_categories[s_category] || {
			commands: [],
			overview: [],
		});
		
		g_category.commands.push(g_command);
		g_category.overview.push(`  ${si_command.padEnd(n_width_column, ' ')}  ${g_command.overview}`);
	}


	// args
	let a_argv = process.argv.slice(2);
	let n_args = a_argv.length;

	// no arguments
	if(!a_argv.length) {
		exit('no arguments given');
	}

	// inputs
	let a_inputs = [];

	// pipeline
	let a_pipeline = [];
	{
		let a_series = [];

		for(let i_argv=0; i_argv<n_args; i_argv++) {
			let s_arg = a_argv[i_argv];

			// after first arg
			if(i_argv) {
				// internal pipe
				if('--pipe' === s_arg) {
					a_pipeline.push(a_series);
					if(i_argv === n_args) {
						exit(`was expecting pipe destination after --pipe: ${a_argv}`);
					}
					a_series = [];
					continue;
				}
				// shorthand internal pipe
				else if('/' === s_arg) {
					a_pipeline.push(a_series);
					if(i_argv === n_args) {
						exit(`was expecting pipe destination after internal pipe character '/': ${a_argv}`);
					}
					a_series = [];
					continue;
				}
				// inputs follow
				else if('--inputs' === s_arg) {
					// convert to readable streams
					a_inputs.push(...a_argv.slice(i_argv+1).map(p => fs.createReadStream(p)));
					break;
				}
			}
			// first arg
			else {
				// main option
				if('-h' === s_arg || '--help' === s_arg) {
					// command overview
					let s_overview = '';
					for(let [s_category, g_category] of Object.entries(h_categories)) {
						s_overview += `${s_category}\n${g_category.overview.join('\n')}\n\n`;
					}

					// eslint-disable-next-line no-console
					console.log(`\nUsage: graphy COMMAND [ / COMMAND]* [--inputs FILES...]\n\n`
						+`Tip: Use the internal pipe operator ' / ' to string together a series of commands.\n\n`
						+s_overview
						+`\nRun 'graphy COMMAND --help' for more information on a command.\n`
						+'\n'+gobble(`
							Examples:
							  1) Find all owl:sameAs triples where the object is a node and different from
							     the subject, then swap the subject and object.
							  
							     graphy read / filter -x '!$object; owl:sameAs; {node}' / transform -j  \\
							         'g => [g.o, g.p, g.s]' / write -c ttl   < input.ttl   > output.ttl

							  (2) 
						`)+'\n'
					);
					process.exit(0);
				}
				// version
				else if('-v' === s_arg || '--version' === s_arg) {
					// eslint-disable-next-line no-console
					console.log(require(path.join(__dirname, './package.json')).version);
					process.exit(0);
				}
			}

			a_series.push(s_arg);
		}

		// empty series
		if(a_series.length) {
			a_pipeline.push(a_series);
		}
	}

	// empty command list
	if(!a_pipeline.length) {
		exit('no commands given');
	}

	(async() => {
		// failure handler
		let f_failure = (e_command) => {
			exit(e_command.message);
		};

		// starting inputs default to stdin if no explicit inputs given
		let a_prev = a_inputs.length? a_inputs: [process.stdin];

		// each series in pipeline
		for(let a_series of a_pipeline) {
			// start with command string
			let s_command = a_series[0];

			// no such command
			if(!(s_command in h_commands)) {
				exit(`no such command '${s_command}'`);
			}

			try {
				// eval command with its args
				let a_curr = await h_commands[s_command](a_series.slice(1), {
					command: s_command,
					inputs: a_prev,
					failure: f_failure,
				});

				// advance inputs
				a_prev = a_curr;
			}
			catch(e_command) {
				exit(e_command.message);
			}
		}

		// expect single output
		if(1 !== a_prev.length) {
			exit(`expected a single output stream but last command produces ${a_prev.length} streams`);
		}

		// pipe output to stdout
		a_prev[0].pipe(process.stdout);
	})();
}
