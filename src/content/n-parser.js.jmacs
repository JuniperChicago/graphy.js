@./* global FORMAT */
@//@

@$ N = true;
@$ NT = 'nt' === FORMAT;
@$ NQ = 'nq' === FORMAT;
@$ QUADS = NQ;

@// import parser macros
@import 'textual-parser-macros.jmacs'

const events = require('events');
const stream = require('stream');

@{constants()}

const R_CLEAN = /\s*(?:#[^\n]*\n\s*)*\s*/y;
const R_LITERAL_ESCAPELESS = /^"([^\\"]*)"(?:\^\^<([^\\>]*)>|@([^ \t.]+)|)?$/;
const R_LITERAL = /^"(.*)"(?:\^\^<(.*)>|@([^ \t.]+)|)?$/;
const R_HAS_ESCAPES = /[\\]/;

@- QUADS
	@$ STATEMENT_REGEX = 'R_QUAD';
	const R_QUAD_ESCAPELESS_SP = /(?:<([^\\>]*)>|_:([^ \t<]+))[ \t]*<([^\\>]*)>[ \t]*(.*?)[ \t]*(?:<([^>]*)>|_:([^ \t<]+)|)[ \t]*\.\s*(?:#[^\n]*\n\s*|\n\s*)+/y;
	const R_QUAD = /(?:<([^>]*)>|_:([^ \t<]+))[ \t]*<([^>]*)>[ \t]*(.*?)[ \t]*(?:<([^>]*)>|_:([^ \t<]+)|)[ \t]*\.\s*(?:#[^\n]*\n\s*|\n\s*)+/y;
@:
	@$ STATEMENT_REGEX = 'R_TRIPLE';
	const R_TRIPLE_ESCAPELESS_SP = /(?:<([^\\>]*)>|_:([^ \t<]+))[ \t]*<([^\\>]*)>[ \t]*(.*?)[ \t]*\.\s*(?:#[^\n]*\n\s*|\n\s*)+/y;
	const R_TRIPLE = /(?:<([^>]*)>|_:([^ \t<]+))[ \t]*<([^>]*)>[ \t]*(.*?)[ \t]*\.\s*(?:#[^\n]*\n\s*|\n\s*)+/y;
@;


@// make prototype function for each rdf object term type
@{term_types()}

const H_DEFAULT_GRAPH = factory.defaultGraph();

const P_IRI_RDFS = 'http://www.w3.org/2000/01/rdf-schema#';
const HP_NN_RDFS_LANG_STRING = factory.namedNode(P_IRI_RDFS+'langString');

@> unescape_iri(term)
	R_HAS_ESCAPES.test(@{term})? @{term}.@{replace_unicode(true)}: @{term}
@;

@> clean()
	// remove whitespace & comments from beginning
	R_CLEAN.lastIndex = 0;
	R_CLEAN.exec(s);

	// update index and prepare to match statement
	let i = R_CLEAN.lastIndex;
@;

@> match_body(match, escape_subject, escape_predicate)
	// prep object term
	let w_object;

	// determine object term type
	let s_object = @{match}[4];

	let x = s_object[0];

	// objet term type is literal
	if('"' === x) {
		// no escapes in string nor datatype
		let m_literal_e = R_LITERAL_ESCAPELESS.exec(s_object);
		if(m_literal_e) {
			// literal has no escapes
			w_object = factory.literal(m_literal_e[1]);

			// set datatype if present
			if(m_literal_e[2]) {
				w_object.datatype = factory.namedNode(m_literal_e[2]);
			}
			// otherwise, set langtag if present
			else if(m_literal_e[3]) {
				w_object.language = m_literal_e[3].toLowerCase();
				w_object.datatype = HP_NN_RDFS_LANG_STRING;
			}
		}
		// escapes in string and/or datatype
		else {
			let m_literal = R_LITERAL.exec(s_object);

			// objet term type is literal
			if(m_literal) {
				// ref literal value
				let s_literal = m_literal[1];

				// string literal has escapes
				if(R_HAS_ESCAPES.test(s_literal)) {
					w_object = factory.literal(this.clean_literal(s_literal));
				}
				// no escapes
				else {
					w_object = factory.literal(s_literal);
				}

				// set datatype if present
				if(m_literal[2]) {
					w_object.datatype = factory.namedNode(@{unescape_iri('m_literal[2]')});
				}
				// otherwise, set langtag if present
				else if(m_literal[3]) {
					w_object.language = m_literal[3].toLowerCase();
					w_object.datatype = HP_NN_RDFS_LANG_STRING;
				}
			}
			else {
				this.s = s;
				return this.parse_error('string literal');
			}
		}
	}
	// object term type is iri; make iri
	else if('<' === x) {
		let p_object = s_object.slice(1, -1);
		w_object = factory.namedNode(@{unescape_iri('p_object')});
	}
	// object term type is blank node; make blank node
	else {
		// object term type is blank node; make blank node
		w_object = factory.blankNode(s_object.substr(2));
	}

	// emit data event
	fk_data(Quad(
		@{match}[1]? factory.namedNode(
			@- escape_subject
				@{unescape_iri(match+'[1]')}
			@:
				@{match}[1]
			@;
			): factory.blankNode(@{match}[2]),
		factory.namedNode(
			@- escape_predicate
				@{unescape_iri(match+'[3]')}
			@:
				@{match}[3]
			@;
			),
		w_object,
		@- QUADS
			@{match}[5]
				? factory.namedNode(@{unescape_iri(match+'[5]')})
				: (@{match}[6]
					? factory.blankNode(@{match}[6])
					: H_DEFAULT_GRAPH)
		@:
			@//@
			H_DEFAULT_GRAPH
		@;
		@//@arguments
	)
		@//@arguments
	);
@;



@> parse_n({
	local: b_local=false,
}={})
	// match @{STATEMENT_TYPE}s
	for(;;) {
		@{if_match(STATEMENT_REGEX+'_ESCAPELESS_SP', 'm_statement_e_sp', true)}
			@{match_body('m_statement_e_sp')}
			
		@{else_if_match(STATEMENT_REGEX, 'm_statement', true)}
			@{match_body('m_statement', true, true)}

		@{else_retry()}
	} // end of while

	// update unparsed data string
	@{b_local? 's_': 'this.'}pre = s.substr(i);
@;


class Parser {
	constructor(g_config) {
		let {
			// input medium
			input: z_input,
		} = g_config;

		// fields
		Object.assign(this, {
			// string buffer
			s: '',

			// string buffer length
			n: 0,

			// left-over string from previous data chunk
			pre: g_config.prepend || '',
		});

		// output stream
		let ds_output;

		// no input given, it will be written/piped in later
		if(null === z_input) {
			// whether or not data has been received before
			let b_init = false;

			// create transform
			ds_output = this.output = new stream.Transform({
				// do not decode strings into buffers
				decodeStrings: false,

				// output quad objects on readable side
				readableObjectMode: true,

				// once there's no more data to consume, invoke eof
				flush: (fk_flush) => {
					// now that stream has ended, clean up remainder
					this.eof(1);

					// done flushing, close read stream
					fk_flush();
				},

				// on data event
				transform: (s_chunk, s_encoding, fk_chunk) => {
					// first transform
					if(!b_init) {
						// notify that data will begin
						ds_output.emit('ready');

						// do not emit 'ready' event again
						b_init = false;
					}

					// stream is paused
					if(this.n < 0) {
						return this.error('stream received new data while it was supposed to be paused!');
					}

					// concatenate current chunk to previous chunk
					let s = this.s = this.pre + s_chunk;

					// cache chunk length
					this.n = s.length;

					// resume parsing
					this.safe_parse(true);

					// emit progress event updates
					ds_output.emit('progress', s_chunk.length);

					// done transforming this chunk
					fk_chunk();
				},
			});

			// bind events to output stream
			this.bind(g_config);

			// notify once and never again
			ds_output.once('pipe', (ds_input) => {
				// input stream has encoding option
				if(ds_input.setEncoding) {
					// ensure stream is encoding in utf8
					ds_input.setEncoding('utf8');
				}
			});
		}
		// input is stream
		else if(z_input.setEncoding) {
			// whether or not data has been received before
			let b_init = false;

			// local
			let s_pre = '';

			let fk_data;

			// begin flowing mode on output stream
			const begin_flow = () => {
				// switch input to flowing mode
				z_input.on('data', (s_chunk) => {
					// // stream is paused
					// if(this.n < 0) {
					// 	return this.error('stream received new data while it was supposed to be paused!');
					// }

					// // notify that data will begin
					// if(!b_init) {
					// 	ds_output.emit('ready');

					// 	// do not notify again
					// 	b_init = true;
					// }
// debugger;
					// concatenate current chunk to previous chunk
					let s = s_pre + s_chunk;

					// cache chunk length
					let n = s.length;

					// remove whitespace & comments from beginning
					R_CLEAN.lastIndex = 0;
					R_CLEAN.exec(s);

					// update index and prepare to match statement
					let i = R_CLEAN.lastIndex;

					// resume parsing
					@{parse_n({
						local: true,
					})}
// debugger;
					this.pre = s_pre;

					// // progress updates
					// ds_output.emit('progress', s_chunk.length);
				});
			};

			// manual read mode
			const read_manual = (nb_read) => {
				// rather than emitting data/other events, queue them
				// this.data = F_QUEUE_DATA;
				this.event = this.queue;

				// subscribe to readable events on input
				z_input.on('readable', () => {
					// read chunk from input stream while there is data to read
					let s_chunk = z_input.read();

					// notify that data will begin
					if(!b_init) {
						ds_output.emit('ready');

						// do not notify again
						b_init = true;
					}

					// concatenate current chunk to previous chunk
					let s = this.s = this.pre + s_chunk;

					// cache chunk length
					this.n = s.length;

					// resume parsing
					this.safe_parse(true);

					// progress updates
					ds_output.emit('progress', s_chunk.length);

					// return ...?
				});
			};

			// create readable output
			ds_output = this.output = new stream.Readable({
				// outputs quad objets
				objectMode: true,

				// this will only happen if consumer uses stream in non-folowing mode
				read(nb_read) {
					// which flowing mode
					switch(ds_output.readableFlowing) {
						// in flowing mode (#pipe, #'data', or #resume)
						case true: {
							// ignore read requests
							ds_output._read = () => {};

							// begin flowing
							begin_flow();
							break;
						}

						// manual reads
						case false:
						case null: {
							// switch to manual read mode
							ds_output._read = read_manual;

							// forward request to handler
							return ds_output._read(nb_read);
						}

						// no mechanism for consuming
						default: {
							debugger;
							// do not start reading input, do not parse, do not emit
						}
					}
				},
			});

			// internal link
			ds_output._graphy_parser = this;

			if(g_config.data) {
				fk_data = g_config.data;
				delete g_config.data;
				begin_flow();
			}
			else {
				fk_data = (g_quad) => ds_output.push(g_quad);
			}

			// bind events to output stream
			this.bind(g_config);

			// set encoding on input stream
			z_input.setEncoding('utf8');

			// once stream closes, invoke eof
			z_input.on('end', () => this.eof());

			// capture error on input
			z_input.on('error', (e_input) => {
				ds_output.emit('error', `error on input stream: ${e_input.message}\n${e_input.stack}`);
			});
		}
		// string
		else if('string' === typeof z_input) {
			// create readable output
			ds_output = this.output = new stream.Readable({
				// outputs quad objets
				objectMode: true,

				// once data event is attached
				read: () => {
					// consume entire string
					this.safe_parse(true);

					// remove this handler
					ds_output._read = () => {};

					// eot
					// debugger;
					this.pre = this.s = null;
					ds_output.push(null);
					g_config.eot();
				},
			});

			// concatenate previous chunk
			// let s = this.s = this.pre+z_input;
			this.pre += z_input;

			// eos means we've reached eof
			if(g_config.async) {
				this.eos = function() {
					setTimeout(() => this.eof(), 0);
				};
			}
			else {
				this.eos = this.eof;
			}

			// compute chunk length
			this.n = this.pre.length;

			// // reset index
			// this.i = 0;

			// remove whitespace & comments from beginning
			R_CLEAN.lastIndex = 0;
			R_CLEAN.exec(this.pre);

			// update index and prepare to match statement
			this.i = R_CLEAN.lastIndex;


			// bind events to output stream
			this.bind(g_config);

			this.data = g_config.data;

			// ready to parse
			ds_output.emit('ready');
		}
		// invalid arg
		else {
			throw new TypeError('invalid argument for input parameter: '+z_input);
		}
	}

	eof() {
		// there is still unparsed data
		if(this.pre.length) {
			// append newline to end so we can match @{STATEMENT_TYPE} token
			this.pre += '\n';
			this.safe_parse();

			// still unparsed characters
			if(this.pre.length) {
				// save string and index before calling parse error
				this.s = this.pre;

				// throw parse error
				return this.parse_error('statement');
			}
		}

		// make buffer's alloc eligible for gc
		this.pre = this.s = null;

		// output stream
		let ds_output = this.output;

		// final progress update: no additional bytes were read
		ds_output.emit('progress', 0);

		// call end event listener
		ds_output.emit('eof');

		// close write stream (EOF-signaling)
		ds_output.push(null);
	}

	parse_error(s_state) {
		throw new Error(`parsing error occurred in state: ${s_state}`);
	}


@$ H_PARSE_EVENTS = {
	error: {},
	read: {once:true},
	progress: {},
	eof: {once:true},
	end: {once:true},
	data: {},  // attach data listener last
};

	bind(g_config) {
		let ds_output = this.output;
		@*{
			for(let [s_event, g_event] of Object.entries(H_PARSE_EVENTS)) {
				yield /* syntax: js */ `
					if(g_config.${s_event}) ds_output.${g_event.once? 'once': 'on'}('${s_event}', g_config.${s_event});
					`.trim()+'\n';
			}
		}
	}

	clean_literal(s_literal) {
		@{unescape('s_literal', '', 's_literal')}
	}

	safe_parse() {
		let s = this.pre;
		let i = this.i;
		let fk_data = this.data;

		@// parse chunk
		@{parse_n()};
	}
}


@{export_module()}
