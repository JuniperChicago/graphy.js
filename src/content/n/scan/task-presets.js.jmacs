
module.exports = {
	count: gc_scan => ({
		reduce: (c_quads_a, c_quads_b) => c_quads_a + c_quads_b,

		run: /* syntax: js */ `
			(read, err, update, submit) => {
				let c_quads = 0;

				return read({
					relax: ${gc_scan.relax? 'true': 'false'},

					data() {
						c_quads += 1;
					},

					error(e_read) {
						err(e_read);
					},

					eof() {
						submit(c_quads);
					},
				});
			}
		`,
	}),

	tree: gc_scan => ({
		// receive: abs_dump => dataset.fromArrayBuffer(abs_dump),
		// receive: h_import => dataset.from(h_import),

		reduce: (k_tree_a, k_tree_b) => k_tree_a.union(k_tree_b),

		run: /* syntax: js */ `
			(read, err, update, submit, user={}, isWorker=false) => {
				let k_dataset = require('@graphy/memory.dataset.fast')();

				return read({
					relax: ${gc_scan.relax? 'true': 'false'},

					pipe: k_dataset.on('finish', () => {
						if(isWorker) {
							// let abs_dump = k_dataset.dump({shared:true});
							// submit(abs_dump, [abs_dump]);
							submit(k_dataset.export());
						}
						else {
							submit(k_dataset);
						}
					}),

					error(e_read) {
						err(e_read);
					},
				});
			}
		`,

		report(k_tree) {
			console.log(k_tree.size);
		},
	}),

	scribe: gc_scan => ({
		run: /* syntax: js */ `
			async(read, err, update, submit, user, isWorker) => {
				// prep buffer string
				let s_buffer = '';

				// create scriber
				let ds_scriber = require('@graphy/content.ttl.scribe')({
					prefixes: user.prefixes,

					// capture scriber output
					data(s_write) {
						s_buffer += s_write;
					},

					// once scriber ends
					end() {
						submit();
					},
				});

				// create reader
				let ds_reader = read({
					relax: ${gc_scan.relax? 'true': 'false'},
				});

				// worker
				if(isWorker) {
					// on reader progress
					ds_reader.on('progress', () => {
						// buffer is not empty
						if(s_buffer) {
							// clean scriber output buffer before sending
							ds_scriber.rinse();

							// convert string -> Buffer -> ArrayBuffer
							let db_chunk = Buffer.from(s_buffer);
							let ab_chunk = db_chunk.buffer.slice(db_chunk.byteOffset, db_chunk.byteOffset+db_chunk.byteLength);

							// send to master
							update(ab_chunk, [ab_chunk]);

							// reset buffer
							s_buffer = '';
						}
					});
				}
				// master
				else {
					// on reader progress
					ds_reader.on('progress', () => {
						// scriber output buffer is not empty
						if(s_buffer) {
							// clean scriber output buffer before sending
							ds_scriber.rinse();

							// empty buffer
							update(s_buffer);

							// reset buffer
							s_buffer = '';
						}
					});
				}

				// pipe reader to scriber
				ds_reader.pipe(ds_scriber);

				// return reader instance
				return ds_reader;
			}
		`,

		// reduce: (ab_chunk_a, ab_chunk_a) => c_quads_a + c_quads_b,

		// update(ab_chunk) {
		// 	this.push(Buffer.from(ab_chunk).toString());
		// },
	}),

	'distinct-quads': gc_scan => ({
		reduce: (k_dataset_a, k_dataset_b) => k_dataset_a.union(k_dataset_b),

		run: /* syntax: js */ `
			(read, err, update, submit, user) => {
				const dataset = require('@graphy/memory.dataset.fast');
				let k_dataset = dataset();

				k_dataset.on('finish', () => {
					submit(k_dataset.export());
				});

				let ds_reader = read({
					relax: ${gc_scan.relax? 'true': 'false'},
				});

				ds_reader.pipe(k_dataset);

				return ds_reader;
			}
		`,
	}),
};
