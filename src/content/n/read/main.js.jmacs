@import '../../../share/iris.jmacs'
@import '../../../share/channel.jmacs'

@./* global FORMAT */
@//@

@$ NT = 'nt' === FORMAT;
@$ NQ = 'nq' === FORMAT;
@$ QUADS = NQ;

@// import parser macros
@import '../../text.read.jmacs'

const stream = require('@{channel('api.iso.stream')}');
const factory = require('@{channel('api.data.factory')}').raw;

const KT_DEFAULT_GRAPH = factory.defaultGraph();
const KT_RDFS_LANG_STRING = factory.namedNode('@{P_IRI_RDFS}langString');

const R_ESCAPES = /@{R_ESCAPES()}/g;
const R_UNICODE_8 = /@{R_UNICODE_8()}/g;
const R_UNICODE_ANY = /@{R_UNICODE_4()}|@{R_UNICODE_8()}/g;

const F_REPLACE_UNICODE_ANY = @{F_REPLACE_UNICODE_ANY()};

const R_CLEAN = /\s*(?:#[^\n]*\n\s*)*\s*/y;
const R_LITERAL_ESCAPELESS = /^"([^\\"]*)"(?:\^\^<([^\\>]*)>|@([^ \t.]+)|)?$/;
const R_LITERAL = /^"(.*)"(?:\^\^<(.*)>|@([^ \t.]+)|)?$/;
const RT_HAS_ESCAPES = /[\\]/;

const RT_NAMED_NODE_VALID = /@{RT_NAMED_NODE_VALID()}/;
const RT_BLANK_NODE_LABEL_VALID = /(?:@{PN_CHARS_U()}|[0-9])(?:(?:@{PN_CHARS()}|[.])*@{PN_CHARS()})?/;
const RT_ESCAPES_INVALID = /\\[^"tbnrfuU\\_~.!$&'()*+,;=/?#@%-]|@{UCHAR('^')}/;
const RT_LITERAL_CONTENTS_VALID = /^([^"\\\n\r]|\\[tbnrf"'\\]|@{UCHAR()})*$/;

@>> R_NAMED_NODE(b_escapeless=false, b_open_cap=false)
	@//@regex
	@{b_open_cap? '(<': '<('}[^@{b_escapeless? '\\\\': ''}>]*)>
@;

@>> R_BLANK_NODE()
	@//@regex
	_:([^\x20\t<]+)
@;

@>> R_NODE(b_escapeless=false, b_open_cap=false)
	@//@regex
	@{R_NAMED_NODE(b_escapeless, b_open_cap)}
	| @{R_BLANK_NODE()}
@;

@>> R_LITERAL(b_escapeless=false)
	@//@regex
	"(@{b_escapeless? '[^"\\\\]': '(?:[^"\\\\]|\\\\")'}*)"(?:\^\^@{R_NAMED_NODE(b_escapeless)}|@([^\x20\t.]+)|)
@;

@>> R_OBJECT(b_escapeless=false)
	@//@regex
	@{R_NODE(b_escapeless, true)}
	| @{R_LITERAL(b_escapeless)}
@;

@>> R_COMMENT()
	@//@regex
	\.\s*(?:#[^\n]*\n\s*|\n\s*)+
@;

@>> R_TRIPLE(b_escapeless=false)
	@//@regex
	(?:@{R_NODE(b_escapeless)})
	[\x20\t]* @{R_NAMED_NODE(b_escapeless)}
	[\x20\t]* (?:@{R_OBJECT(b_escapeless)})
	[\x20\t]* @{R_COMMENT()}
@;

@>> R_QUAD(b_escapeless=false)
	@//@regex
	(?:@{R_NODE(b_escapeless)})
	[\x20\t]* @{R_NAMED_NODE(b_escapeless)}
	[\x20\t]* (?:@{R_OBJECT(b_escapeless)})
	[\x20\t]* (?:@{R_NAMED_NODE(b_escapeless)}|)
	[\x20\t]* @{R_COMMENT()}
@;

@- QUADS
	@$ STATEMENT_REGEX = 'R_QUAD';

	const R_QUAD_ESCAPELESS_SP = /@{R_QUAD(true)}/y;
	const R_QUAD = /@{R_QUAD()}/y;

	// const R_QUAD_ESCAPELESS_SP = /(?:<([^\\>]*)>|_:([^ \t<]+))[ \t]*<([^\\>]*)>[ \t]*(?:<([^\\>]*)>|_:([^ \t<]+)|"[^"]*"())[ \t]*(?:<([^>]*)>|_:([^ \t<]+)|)[ \t]*\.\s*(?:#[^\n]*\n\s*|\n\s*)+/y;
	// const R_QUAD = /(?:<([^>]*)>|_:([^ \t<]+))[ \t]*<([^>]*)>[ \t]*(.*?)[ \t]*(?:<([^>]*)>|_:([^ \t<]+)|)[ \t]*\.\s*(?:#[^\n]*\n\s*|\n\s*)+/y;
@:
	@$ STATEMENT_REGEX = 'R_TRIPLE';

	const R_TRIPLE_ESCAPELESS_SP = /@{R_TRIPLE(true)}/y;
	const R_TRIPLE = /@{R_TRIPLE()}/y;

	// const R_TRIPLE_ESCAPELESS_SP = /(?:<([^\\>]*)>|_:([^ \t<]+))[ \t]*<([^\\>]*)>[ \t]*(.*?)[ \t]*\.\s*(?:#[^\n]*\n\s*|\n\s*)+/y;
	// const R_TRIPLE = /(?:<([^>]*)>|_:([^ \t<]+))[ \t]*<([^>]*)>[ \t]*(.*?)[ \t]*\.\s*(?:#[^\n]*\n\s*|\n\s*)+/y;
@;


@> unescape_iri(term)
	RT_HAS_ESCAPES.test(@{term})? @{term}.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): @{term}
@;

@> clean()
	// remove whitespace & comments from beginning
	R_CLEAN.lastIndex = 0;
	R_CLEAN.exec(s);

	// update index and prepare to match statement
	let i = R_CLEAN.lastIndex;
@;

@.{
	const ue_iri = (sv_iri, b_unescape=false) => b_unescape? unescape_iri(sv_iri): sv_iri;
}

@> match_body(sv_match, b_unescape=false)
	// prep object term
	let w_object;

	// object term type is named node
	if(@{sv_match}[4]) {
		let p_object = @{sv_match}[4].slice(1);
		w_object = this.namedNode(@{ue_iri('p_object', b_unescape)});
	}
	// object term type is blank node
	else if(@{sv_match}[5]) {
		w_object = this.blankNode(@{ue_iri(sv_match+'[5]', b_unescape)});
	}
	// object term type is literal
	else {
		// contents
		w_object = this.literal(@{sv_match}[6], @{b_unescape});

		// set datatype if present
		if(@{sv_match}[7]) {
			w_object.datatype = this.namedNode(@{ue_iri(sv_match+'[7]', b_unescape)});
		}
		// otherwise, set language tag if present
		else if(@{sv_match}[8]) {
			w_object.language = @{sv_match}[8].toLowerCase();
			w_object.datatype = KT_RDFS_LANG_STRING;
		}
	}

	// emit data event
	fk_data(
		factory.quad(
			@{sv_match}[2]
				? this.blankNode(@{sv_match}[2])
				: this.namedNode(@{ue_iri(sv_match+'[1]', b_unescape)}),
			this.namedNode(@{ue_iri(sv_match+'[3]', b_unescape)}),
			w_object,
			@- QUADS
				@{sv_match}[9]
					? this.namedNode(@{ue_iri(sv_match+'[9]', b_unescape)})
					: (@{sv_match[10]}
						? this.blankNode(@{sv_match}[10])
						: ('string' === typeof @{sv_match[9]}
							? this.namedNode(@{ue_iri(sv_match+'[9]', b_unescape)})
							: KT_DEFAULT_GRAPH))
			@:
				@//@
				KT_DEFAULT_GRAPH
			@;
			@//@arguments
		)
		@//@arguments
	);
@;



@> parse_n({
	local: b_local=false,
}={})
	// match triples/quads
	for(;;) {
		@{if_match(STATEMENT_REGEX+'_ESCAPELESS_SP', 'm_statement_e_sp', true)}
			@{match_body('m_statement_e_sp')}
			
		@{else_if_match(STATEMENT_REGEX, 'm_statement', true)}
			@{match_body('m_statement', true)}

		@{else_retry()}
	} // end of while

	// update unparsed data string
	@{b_local? 's_': 'this.'}pre = s.substr(i);
@;


class reader {
	constructor(g_config) {
		let {
			// input medium
			input: g_input,

			// validate iris
			validate: b_validate=false,
		} = g_config;

		// fields
		Object.assign(this, {
			// string buffer
			s: '',

			// string buffer length
			n: 0,

			// left-over string from previous data chunk
			pre: g_config.prepend || '',
		});

		// validation
		Object.assign(this, b_validate
			? {
				namedNode(s_iri) {
					if(!RT_NAMED_NODE_VALID.test(s_iri)) return this._error(`invalid IRI: "${s_iri}"`);
					return factory.namedNode(s_iri);
				},

				blankNode(s_label) {
					if(!RT_BLANK_NODE_LABEL_VALID.test(s_label)) return this._error(`invalid blank node label: "${s_label}"`);
					return factory.blankNode(s_label);
				},

				literal(s_literal, b_unescape=false) {
					if(!RT_LITERAL_CONTENTS_VALID.test(s_literal)) return this._error(`invalid literal: "${s_literal}"`);
					try {
						return factory.literal(b_unescape? @{unescape_literal('s_literal')}: s_literal);
					}
					catch(e_parse) {
						return this._error(`invalid string literal: "${s_literal}"`);
					}
				},
			}
			: {
				namedNode: factory.namedNode,

				blankNode: factory.blankNode,

				literal: (s_literal, b_unescape) => factory.literal(b_unescape? @{unescape_literal('s_literal')}: s_literal),
			});

		// output stream
		let ds_output;

		// no input given, it will be written/piped in later
		if(null === g_input) {
			// whether or not data has been received before
			let b_init = false;

			// create transform
			ds_output = this.output = new stream.Transform({
				// do not decode strings into buffers
				decodeStrings: false,

				// output quad objects on readable side
				readableObjectMode: true,

				// once there's no more data to consume, invoke eof
				flush: (fk_flush) => {
					// now that stream has ended, clean up remainder
					this.eof(1);

					// done flushing, close read stream
					fk_flush();
				},

				// on data event
				transform: (s_chunk, s_encoding, fk_chunk) => {
					// first transform
					if(!b_init) {
						// notify that data will begin
						ds_output.emit('ready');

						// do not emit 'ready' event again
						b_init = false;
					}

					// stream is paused
					if(this.n < 0) {
						return this.error('stream received new data while it was supposed to be paused!');
					}

					// concatenate current chunk to previous chunk
					let s = this.s = this.pre + s_chunk;

					// cache chunk length
					this.n = s.length;

					// resume parsing
					this.safe_parse(true);

					// emit progress event updates
					ds_output.emit('progress', s_chunk.length);

					// done transforming this chunk
					fk_chunk();
				},
			});

			// bind events to output stream
			this.bind(g_config);

			// notify once and never again
			ds_output.once('pipe', (ds_input) => {
				// input stream has encoding option
				if(ds_input.setEncoding) {
					// ensure stream is encoding in utf8
					ds_input.setEncoding('utf8');
				}
			});
		}
		// input is stream
		else if(g_input.stream) {
			let ds_input = g_input.stream;

			// whether or not data has been received before
			let b_init = false;

			// local
			let s_pre = '';

			let fk_data;

			// begin flowing mode on output stream
			const begin_flow = () => {
				// switch input to flowing mode
				ds_input.on('data', (s_chunk) => {
					// concatenate current chunk to previous chunk
					let s = s_pre + s_chunk;

					// remove whitespace & comments from beginning
					R_CLEAN.lastIndex = 0;
					R_CLEAN.exec(s);

					// update index and prepare to match statement
					let i = R_CLEAN.lastIndex;

					// resume parsing
					@{parse_n({
						local: true,
					})}

					this.pre = s_pre;

					// progress updates
					ds_output.emit('progress', s_chunk.length);
				});
			};

			// manual read mode
			const read_manual = (nb_read) => {
				// rather than emitting data/other events, queue them
				// this.data = F_QUEUE_DATA;
				this.event = this.queue;

				// subscribe to readable events on input
				ds_input.on('readable', () => {
					// read chunk from input stream while there is data to read
					let s_chunk = ds_input.read();

					// notify that data will begin
					if(!b_init) {
						ds_output.emit('ready');

						// do not notify again
						b_init = true;
					}

					// concatenate current chunk to previous chunk
					let s = this.s = this.pre + s_chunk;

					// cache chunk length
					this.n = s.length;

					// resume parsing
					this.safe_parse(true);

					// progress updates
					ds_output.emit('progress', s_chunk.length);

					// return ...?
				});
			};

			// create readable output
			ds_output = this.output = new stream.Readable({
				// outputs quad objets
				objectMode: true,

				// this will only happen if consumer uses stream in non-folowing mode
				read(nb_read) {
					// which flowing mode
					switch(ds_output.readableFlowing) {
						// in flowing mode (#pipe, #'data', or #resume)
						case true: {
							// ignore read requests
							ds_output._read = () => {};

							// begin flowing
							begin_flow();
							break;
						}

						// manual reads
						case false:
						case null: {
							// switch to manual read mode
							ds_output._read = read_manual;

							// forward request to handler
							return ds_output._read(nb_read);
						}

						// no mechanism for consuming
						default: {
							debugger;
							// do not start reading input, do not parse, do not emit
						}
					}
				},
			});

			// internal link
			ds_output._graphy_reader = this;

			// inline data callback
			if(g_config.data) {
				fk_data = g_config.data;

				// on new event listener
				ds_output.on('newListener', function fk_add_listener(s_event) {
					// a data listener was added
					if('data' === s_event) {
						// hold onto inline callback
						let fk_hoc = fk_data;

						// combine listeners
						fk_data = (g_quad) => {
							fk_hoc(g_quad);
							ds_output.push(g_quad);
						};

						// don't do this again
						ds_output.removeListener('newListener', fk_add_listener);
					}
				});

				delete g_config.data;
				begin_flow();
			}
			else {
				fk_data = (g_quad) => ds_output.push(g_quad);
			}

			// bind events to output stream
			this.bind(g_config);

			// set encoding on input stream
			ds_input.setEncoding('utf8');

			// once stream closes, invoke eof
			ds_input.on('end', () => this.eof());

			// capture error on input
			ds_input.on('error', (e_input) => {
				ds_output.emit('error', `error on input stream: ${e_input.message}\n${e_input.stack}`);
			});
		}
		// string
		else if(g_input.string) {
			let s_input = g_input.string;

			// create readable output
			ds_output = this.output = new stream.Readable({
				// outputs quad objets
				objectMode: true,

				// once data event is attached
				read: () => {
					// consume entire string
					this.safe_parse(true);

					// remove this handler
					ds_output._read = () => {};

					// eot
					// debugger;
					this.pre = this.s = null;
					ds_output.push(null);
					g_config.end();
				},
			});

			// concatenate previous chunk
			// let s = this.s = this.pre+z_input;
			this.pre += s_input;

			// eos means we've reached eof
			if(g_config.async) {
				this.eos = function() {
					setTimeout(() => this.eof(), 0);
				};
			}
			else {
				this.eos = this.eof;
			}

			// compute chunk length
			this.n = this.pre.length;

			// // reset index
			// this.i = 0;

			// remove whitespace & comments from beginning
			R_CLEAN.lastIndex = 0;
			R_CLEAN.exec(this.pre);

			// update index and prepare to match statement
			this.i = R_CLEAN.lastIndex;


			// bind events to output stream
			this.bind(g_config);

			this.data = g_config.data;

			// ready to parse
			ds_output.emit('ready');
		}
		// invalid arg
		else {
			throw new TypeError('invalid input: '+('object' === typeof g_input? JSON.stringify(g_input): g_input));
		}
	}

	eof() {
		// there is still unparsed data
		if(this.pre.length) {
			// append newline to end so we can match token
			this.pre += '\n';
			this.safe_parse();

			// still unparsed characters
			if(this.pre.length) {
				// save string and index before calling parse error
				this.s = this.pre;

				// throw parse error
				return this.parse_error('statement');
			}
		}

		// make buffer's alloc eligible for gc
		this.pre = this.s = null;

		// output stream
		let ds_output = this.output;

		// final progress update: no additional bytes were read
		ds_output.emit('progress', 0);

		// call end event listener
		ds_output.emit('eof');

		// close write stream (EOF-signaling)
		ds_output.push(null);
	}

	_error(s_message) {
		throw new Error(s_message);
	}

	parse_error(s_state) {
		throw new Error(`parsing error occurred in state: ${s_state}`);
	}


@$ H_PARSE_EVENTS = {
	error: {},
	read: {once:true},
	progress: {},
	eof: {once:true},
	end: {}, // {once:true},
	data: {},  // attach data listener last
};

	bind(g_config) {
		let ds_output = this.output;
		@*{
			for(let [s_event, g_event] of Object.entries(H_PARSE_EVENTS)) {
				yield /* syntax: js */ `
					if(g_config.${s_event}) ds_output.${g_event.once? 'once': 'on'}('${s_event}', g_config.${s_event});
					`.trim()+'\n';
			}
		}
	}

	safe_parse() {
		let s = this.pre;
		let i = this.i;
		let fk_data = this.data;

		@// parse chunk
		@{parse_n()};
	}
}


const read = module.exports = function(...a_args) {
	let g_config = {};

	@{normalize_reader_config('g_config')}

	// create reader, return output stream
	return (new reader(g_config)).output;
};
