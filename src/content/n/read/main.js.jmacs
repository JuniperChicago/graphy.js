@import '../../../share/iris.jmacs'
@import '../../../share/channel.jmacs'

@./* global FORMAT */
@//@

@$ NT = 'nt' === FORMAT;
@$ NQ = 'nq' === FORMAT;
@$ QUADS = NQ;

@// import parser macros
@import '../../common.parse.textual.jmacs'

const stream = require('@{channel('api.iso.stream')}');
const factory = require('@{channel('api.data.factory')}').raw;

const KT_DEFAULT_GRAPH = factory.defaultGraph();
const KT_RDFS_LANG_STRING = factory.namedNode('@{P_IRI_RDFS}langString');

const R_ESCAPES = /@{R_ESCAPES()}/g;
const R_UNICODE_8 = /@{R_UNICODE_8()}/g;
const R_UNICODE_ANY = /@{R_UNICODE_4()}|@{R_UNICODE_8()}/g;

const F_REPLACE_UNICODE_ANY = @{F_REPLACE_UNICODE_ANY()};

const R_CLEAN = /\s*(?:#[^\n]*\n\s*)*\s*/y;
const R_LITERAL_ESCAPELESS = /^"([^\\"]*)"(?:\^\^<([^\\>]*)>|@([^ \t.]+)|)?$/;
const R_LITERAL = /^"(.*)"(?:\^\^<(.*)>|@([^ \t.]+)|)?$/;
const RT_HAS_ESCAPES = /[\\]/;

const RT_NAMED_NODE_VALID = /@{RT_NAMED_NODE_VALID()}/;
const RT_ESCAPES_INVALID = /\\[^"tbnrfuU\\_~.!$&'()*+,;=/?#@%-]|@{UCHAR('^')}/;

@- QUADS
	@$ STATEMENT_REGEX = 'R_QUAD';
	const R_QUAD_ESCAPELESS_SP = /(?:<([^\\>]*)>|_:([^ \t<]+))[ \t]*<([^\\>]*)>[ \t]*(.*?)[ \t]*(?:<([^>]*)>|_:([^ \t<]+)|)[ \t]*\.\s*(?:#[^\n]*\n\s*|\n\s*)+/y;
	const R_QUAD = /(?:<([^>]*)>|_:([^ \t<]+))[ \t]*<([^>]*)>[ \t]*(.*?)[ \t]*(?:<([^>]*)>|_:([^ \t<]+)|)[ \t]*\.\s*(?:#[^\n]*\n\s*|\n\s*)+/y;
@:
	@$ STATEMENT_REGEX = 'R_TRIPLE';
	const R_TRIPLE_ESCAPELESS_SP = /(?:<([^\\>]*)>|_:([^ \t<]+))[ \t]*<([^\\>]*)>[ \t]*(.*?)[ \t]*\.\s*(?:#[^\n]*\n\s*|\n\s*)+/y;
	const R_TRIPLE = /(?:<([^>]*)>|_:([^ \t<]+))[ \t]*<([^>]*)>[ \t]*(.*?)[ \t]*\.\s*(?:#[^\n]*\n\s*|\n\s*)+/y;
@;


@> unescape_iri(term)
	RT_HAS_ESCAPES.test(@{term})? @{term}.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): @{term}
@;

@> clean()
	// remove whitespace & comments from beginning
	R_CLEAN.lastIndex = 0;
	R_CLEAN.exec(s);

	// update index and prepare to match statement
	let i = R_CLEAN.lastIndex;
@;

@> match_body(sv_match, escape_subject, escape_predicate)
	// prep object term
	let w_object;

	// determine object term type
	let s_object = @{sv_match}[4];

	let x = s_object[0];

	// objet term type is literal
	if('"' === x) {
		// no escapes in string nor datatype
		let m_literal_e = R_LITERAL_ESCAPELESS.exec(s_object);
		if(m_literal_e) {
			// literal has no escapes
			w_object = this.literal(m_literal_e[1]);

			// set datatype if present
			if(m_literal_e[2]) {
				w_object.datatype = this.namedNode(m_literal_e[2]);
			}
			// otherwise, set langtag if present
			else if(m_literal_e[3]) {
				w_object.language = m_literal_e[3].toLowerCase();
				w_object.datatype = KT_RDFS_LANG_STRING;
			}
		}
		// escapes in string and/or datatype
		else {
			let m_literal = R_LITERAL.exec(s_object);

			// objet term type is literal
			if(m_literal) {
				// ref literal value
				let s_literal = m_literal[1];

				// string literal has escapes
				if(RT_HAS_ESCAPES.test(s_literal)) {
					w_object = this.literal(@{unescape_literal('s_literal')});
				}
				// no escapes
				else {
					w_object = this.literal(s_literal);
				}

				// set datatype if present
				if(m_literal[2]) {
					w_object.datatype = this.namedNode(@{unescape_iri('m_literal[2]')});
				}
				// otherwise, set langtag if present
				else if(m_literal[3]) {
					w_object.language = m_literal[3].toLowerCase();
					w_object.datatype = KT_RDFS_LANG_STRING;
				}
			}
			else {
				this.s = s;
				return this.parse_error('string literal');
			}
		}
	}
	// object term type is iri; make iri
	else if('<' === x) {
		let p_object = s_object.slice(1, -1);
		w_object = this.namedNode(@{unescape_iri('p_object')});
	}
	// object term type is blank node; make blank node
	else {
		// object term type is blank node; make blank node
		w_object = factory.blankNode(s_object.substr(2));
	}

	// emit data event
	fk_data(factory.quad(
		@{sv_match}[1]? this.namedNode(
			@- escape_subject
				@{unescape_iri(sv_match+'[1]')}
			@:
				@{sv_match}[1]
			@;
			): factory.blankNode(@{sv_match}[2]),
		this.namedNode(
			@- escape_predicate
				@{unescape_iri(sv_match+'[3]')}
			@:
				@{sv_match}[3]
			@;
			),
		w_object,
		@- QUADS
			@{sv_match}[5]
				? this.namedNode(@{unescape_iri(sv_match+'[5]')})
				: (@{sv_match}[6]
					? factory.blankNode(@{sv_match}[6])
					: KT_DEFAULT_GRAPH)
		@:
			@//@
			KT_DEFAULT_GRAPH
		@;
		@//@arguments
	)
		@//@arguments
	);
@;



@> parse_n({
	local: b_local=false,
}={})
	// match @{STATEMENT_TYPE}s
	for(;;) {
		@{if_match(STATEMENT_REGEX+'_ESCAPELESS_SP', 'm_statement_e_sp', true)}
			@{match_body('m_statement_e_sp')}
			
		@{else_if_match(STATEMENT_REGEX, 'm_statement', true)}
			@{match_body('m_statement', true, true)}

		@{else_retry()}
	} // end of while

	// update unparsed data string
	@{b_local? 's_': 'this.'}pre = s.substr(i);
@;


class reader {
	constructor(g_config) {
		let {
			// input medium
			input: g_input,

			// validate iris
			validate: b_validate=false,
		} = g_config;

		// fields
		Object.assign(this, {
			// string buffer
			s: '',

			// string buffer length
			n: 0,

			// left-over string from previous data chunk
			pre: g_config.prepend || '',
		});

		// validation
		Object.assign(this, b_validate
			? {
				namedNode(s_iri) {
					if(!RT_NAMED_NODE_VALID.test(s_iri)) return this._error(`invalid IRI: "${s_iri}"`);
					return factory.namedNode(s_iri);
				},

				literal(s_literal) {
					if(RT_ESCAPES_INVALID.test(s_literal)) return this._error(`invalid literal: "${s_literal}"`);
					try {
						return @{unescape_literal('s_literal')};
					}
					catch(e_parse) {
						return this._error(`invalid string literal: "${s_literal}"`);
					}
				},
			}
			: {
				namedNode: factory.namedNode,

				literal: factory.literal,
			});

		// output stream
		let ds_output;

		// no input given, it will be written/piped in later
		if(null === g_input) {
			// whether or not data has been received before
			let b_init = false;

			// create transform
			ds_output = this.output = new stream.Transform({
				// do not decode strings into buffers
				decodeStrings: false,

				// output quad objects on readable side
				readableObjectMode: true,

				// once there's no more data to consume, invoke eof
				flush: (fk_flush) => {
					// now that stream has ended, clean up remainder
					this.eof(1);

					// done flushing, close read stream
					fk_flush();
				},

				// on data event
				transform: (s_chunk, s_encoding, fk_chunk) => {
					// first transform
					if(!b_init) {
						// notify that data will begin
						ds_output.emit('ready');

						// do not emit 'ready' event again
						b_init = false;
					}

					// stream is paused
					if(this.n < 0) {
						return this.error('stream received new data while it was supposed to be paused!');
					}

					// concatenate current chunk to previous chunk
					let s = this.s = this.pre + s_chunk;

					// cache chunk length
					this.n = s.length;

					// resume parsing
					this.safe_parse(true);

					// emit progress event updates
					ds_output.emit('progress', s_chunk.length);

					// done transforming this chunk
					fk_chunk();
				},
			});

			// bind events to output stream
			this.bind(g_config);

			// notify once and never again
			ds_output.once('pipe', (ds_input) => {
				// input stream has encoding option
				if(ds_input.setEncoding) {
					// ensure stream is encoding in utf8
					ds_input.setEncoding('utf8');
				}
			});
		}
		// input is stream
		else if(g_input.stream) {
			let ds_input = g_input.stream;

			// whether or not data has been received before
			let b_init = false;

			// local
			let s_pre = '';

			let fk_data;

			// begin flowing mode on output stream
			const begin_flow = () => {
				// switch input to flowing mode
				ds_input.on('data', (s_chunk) => {
					// // stream is paused
					// if(this.n < 0) {
					// 	return this.error('stream received new data while it was supposed to be paused!');
					// }

					// // notify that data will begin
					// if(!b_init) {
					// 	ds_output.emit('ready');

					// 	// do not notify again
					// 	b_init = true;
					// }
// debugger;
					// concatenate current chunk to previous chunk
					let s = s_pre + s_chunk;

					// cache chunk length
					let n = s.length;

					// remove whitespace & comments from beginning
					R_CLEAN.lastIndex = 0;
					R_CLEAN.exec(s);

					// update index and prepare to match statement
					let i = R_CLEAN.lastIndex;

					// resume parsing
					@{parse_n({
						local: true,
					})}
// debugger;
					this.pre = s_pre;

					// // progress updates
					// ds_output.emit('progress', s_chunk.length);
				});
			};

			// manual read mode
			const read_manual = (nb_read) => {
				// rather than emitting data/other events, queue them
				// this.data = F_QUEUE_DATA;
				this.event = this.queue;

				// subscribe to readable events on input
				ds_input.on('readable', () => {
					// read chunk from input stream while there is data to read
					let s_chunk = ds_input.read();

					// notify that data will begin
					if(!b_init) {
						ds_output.emit('ready');

						// do not notify again
						b_init = true;
					}

					// concatenate current chunk to previous chunk
					let s = this.s = this.pre + s_chunk;

					// cache chunk length
					this.n = s.length;

					// resume parsing
					this.safe_parse(true);

					// progress updates
					ds_output.emit('progress', s_chunk.length);

					// return ...?
				});
			};

			// create readable output
			ds_output = this.output = new stream.Readable({
				// outputs quad objets
				objectMode: true,

				// this will only happen if consumer uses stream in non-folowing mode
				read(nb_read) {
					// which flowing mode
					switch(ds_output.readableFlowing) {
						// in flowing mode (#pipe, #'data', or #resume)
						case true: {
							// ignore read requests
							ds_output._read = () => {};

							// begin flowing
							begin_flow();
							break;
						}

						// manual reads
						case false:
						case null: {
							// switch to manual read mode
							ds_output._read = read_manual;

							// forward request to handler
							return ds_output._read(nb_read);
						}

						// no mechanism for consuming
						default: {
							debugger;
							// do not start reading input, do not parse, do not emit
						}
					}
				},
			});

			// internal link
			ds_output._graphy_reader = this;

			// inline data callback
			if(g_config.data) {
				fk_data = g_config.data;

				// on new event listener
				ds_output.on('newListener', function fk_add_listener(s_event) {
					// a data listener was added
					if('data' === s_event) {
						// hold onto inline callback
						let fk_hoc = fk_data;

						// combine listeners
						fk_data = (g_quad) => {
							fk_hoc(g_quad);
							ds_output.push(g_quad);
						};

						// don't do this again
						ds_output.removeListener('newListener', fk_add_listener);
					}
				});

				delete g_config.data;
				begin_flow();
			}
			else {
				fk_data = (g_quad) => ds_output.push(g_quad);
			}

			// bind events to output stream
			this.bind(g_config);

			// set encoding on input stream
			ds_input.setEncoding('utf8');

			// once stream closes, invoke eof
			ds_input.on('end', () => this.eof());

			// capture error on input
			ds_input.on('error', (e_input) => {
				ds_output.emit('error', `error on input stream: ${e_input.message}\n${e_input.stack}`);
			});
		}
		// string
		else if(g_input.string) {
			let s_input = g_input.string;

			// create readable output
			ds_output = this.output = new stream.Readable({
				// outputs quad objets
				objectMode: true,

				// once data event is attached
				read: () => {
					// consume entire string
					this.safe_parse(true);

					// remove this handler
					ds_output._read = () => {};

					// eot
					// debugger;
					this.pre = this.s = null;
					ds_output.push(null);
					g_config.end();
				},
			});

			// concatenate previous chunk
			// let s = this.s = this.pre+z_input;
			this.pre += s_input;

			// eos means we've reached eof
			if(g_config.async) {
				this.eos = function() {
					setTimeout(() => this.eof(), 0);
				};
			}
			else {
				this.eos = this.eof;
			}

			// compute chunk length
			this.n = this.pre.length;

			// // reset index
			// this.i = 0;

			// remove whitespace & comments from beginning
			R_CLEAN.lastIndex = 0;
			R_CLEAN.exec(this.pre);

			// update index and prepare to match statement
			this.i = R_CLEAN.lastIndex;


			// bind events to output stream
			this.bind(g_config);

			this.data = g_config.data;

			// ready to parse
			ds_output.emit('ready');
		}
		// invalid arg
		else {
			throw new TypeError('invalid input: '+('object' === typeof g_input? JSON.stringify(g_input): g_input));
		}
	}

	eof() {
		// there is still unparsed data
		if(this.pre.length) {
			// append newline to end so we can match @{STATEMENT_TYPE} token
			this.pre += '\n';
			this.safe_parse();

			// still unparsed characters
			if(this.pre.length) {
				// save string and index before calling parse error
				this.s = this.pre;

				// throw parse error
				return this.parse_error('statement');
			}
		}

		// make buffer's alloc eligible for gc
		this.pre = this.s = null;

		// output stream
		let ds_output = this.output;

		// final progress update: no additional bytes were read
		ds_output.emit('progress', 0);

		// call end event listener
		ds_output.emit('eof');

		// close write stream (EOF-signaling)
		ds_output.push(null);
	}

	parse_error(s_state) {
		throw new Error(`parsing error occurred in state: ${s_state}`);
	}


@$ H_PARSE_EVENTS = {
	error: {},
	read: {once:true},
	progress: {},
	eof: {once:true},
	end: {once:true},
	data: {},  // attach data listener last
};

	bind(g_config) {
		let ds_output = this.output;
		@*{
			for(let [s_event, g_event] of Object.entries(H_PARSE_EVENTS)) {
				yield /* syntax: js */ `
					if(g_config.${s_event}) ds_output.${g_event.once? 'once': 'on'}('${s_event}', g_config.${s_event});
					`.trim()+'\n';
			}
		}
	}

	safe_parse() {
		let s = this.pre;
		let i = this.i;
		let fk_data = this.data;

		@// parse chunk
		@{parse_n()};
	}
}


const read = module.exports = function(...a_args) {
	let g_config = {};

	@{normalize_reader_config('g_config')}

	// create reader, return output stream
	return (new reader(g_config)).output;
};
