@import '../../../share/iris.jmacs'
@import '../../../share/channel.jmacs'

@./* global FORMAT */
@//@

@$ NT = 'nt' === FORMAT;
@$ NQ = 'nq' === FORMAT;
@$ QUADS = NQ;

@// import parser macros
@import '../../text.read.jmacs'

const stream = require('@{channel('core.iso.stream')}');
const factory = require('@{channel('core.data.factory')}').raw;

const KT_DEFAULT_GRAPH = factory.defaultGraph();
const KT_RDFS_LANG_STRING = factory.namedNode('@{P_IRI_RDFS}langString');

const R_ESCAPES = /@{R_ESCAPES()}/g;
const R_UNICODE_8 = /@{R_UNICODE_8()}/g;
const R_UNICODE_ANY = /@{R_UNICODE_4()}|@{R_UNICODE_8()}/g;

const F_REPLACE_UNICODE_ANY = @{F_REPLACE_UNICODE_ANY()};

const R_CLEAN = /\s*(?:#[^\n]*\n\s*)*\s*/y;
const R_CLEAN_COMMENTS = /\s*(#[^\n]*\n\s*)*\s*/y;
const R_LITERAL_ESCAPELESS = /^"([^\\"]*)"(?:\^\^<([^\\>]*)>|@([^ \t.]+)|)?$/;
const R_LITERAL = /^"(.*)"(?:\^\^<(.*)>|@([^ \t.]+)|)?$/;
const RT_HAS_ESCAPES = /[\\]/;

const RT_ABSOLUTE_IRI_VALID = /^[a-z][a-z0-9+\-.]*:([^\0-\x20<>"{}|^`\\]|@{UCHAR()})*$/;
const RT_BLANK_NODE_LABEL_VALID = /^(?:[@{RANGE_PN_CHARS_U()}0-9])(?:(?:[@{RANGE_PN_CHARS()}.])*[@{RANGE_PN_CHARS()}])?$/u;
const RT_ESCAPES_INVALID = /\\[^"tbnrfuU\\_~.!$&'()*+,;=/?#@%-]|@{UCHAR('^')}/;
const RT_LITERAL_CONTENTS_VALID = /^([^"\\\n\r]|\\[tbnrf"'\\]|@{UCHAR()})*$/;
const RT_LANGUAGE_VALID = /^[a-z]+(-[a-z0-9]+)*$/;

@>> R_NAMED_NODE(b_escapeless=false, b_open_cap=false)
	@//@regex
	@{b_open_cap? '(<': '<('}[^@{b_escapeless? '\\\\': ''}>]*)>
@;

@>> R_BLANK_NODE()
	@//@regex
	_:([^\x20\t<]+)
@;

@>> R_NODE(b_escapeless=false, b_open_cap=false)
	@//@regex
	@{R_NAMED_NODE(b_escapeless, b_open_cap)}
	| @{R_BLANK_NODE()}
@;

@>> R_LITERAL(b_escapeless=false)
	@//@regex
	"(@{b_escapeless? '[^"\\\\]': '(?:[^"\\\\]|\\\\.)'}*)"(?:\^\^@{R_NAMED_NODE(b_escapeless)}|@([^\x20\t.]+)|)
@;

@>> R_OBJECT(b_escapeless=false)
	@//@regex
	@{R_NODE(b_escapeless, true)}
	| @{R_LITERAL(b_escapeless)}
@;

@>> R_COMMENT()
	@//@regex
	\.\s*(#[^\n]*\n\s*|\n\s*)+
@;

@>> R_TRIPLE(b_escapeless=false)
	@//@regex
	(?:@{R_NODE(b_escapeless)})
	[\x20\t]* @{R_NAMED_NODE(b_escapeless)}
	[\x20\t]* (?:@{R_OBJECT(b_escapeless)})
	[\x20\t]* @{R_COMMENT()}
@;

@>> R_QUAD(b_escapeless=false)
	@//@regex
	(?:@{R_NODE(b_escapeless)})
	[\x20\t]* @{R_NAMED_NODE(b_escapeless)}
	[\x20\t]* (?:@{R_OBJECT(b_escapeless)})
	[\x20\t]* (?:@{R_NODE(b_escapeless)}|)
	[\x20\t]* @{R_COMMENT()}
@;

@- QUADS
	@$ STATEMENT_REGEX = 'R_QUAD';

	const R_QUAD_ESCAPELESS_SP = /@{R_QUAD(true)}/y;
	const R_QUAD = /@{R_QUAD()}/y;
@:
	@$ STATEMENT_REGEX = 'R_TRIPLE';

	const R_TRIPLE_ESCAPELESS_SP = /@{R_TRIPLE(true)}/y;
	const R_TRIPLE = /@{R_TRIPLE()}/y;
@;


@> unescape_iri(term)
	RT_HAS_ESCAPES.test(@{term})? @{term}.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): @{term}
@;

@> clean()
	// remove whitespace & comments from beginning
	R_CLEAN.lastIndex = 0;
	let m_clean = R_CLEAN.exec(s);

	// comments
	if(this.emit_comments) {
		this.emit_comments(m_clean[1]);
	}

	// update index and prepare to match statement
	let i = R_CLEAN.lastIndex;
@;

@.{
	const ue_iri = (sv_iri, b_unescape=false) => b_unescape? unescape_iri(sv_iri): sv_iri;
}

@> match_body(sv_match, b_unescape=false)
	// prep object term
	let w_object;

	// object term type is named node
	if(@{sv_match}[4]) {
		let p_object = @{sv_match}[4].slice(1);
		w_object = this.namedNode(@{ue_iri('p_object', b_unescape)});
	}
	// object term type is blank node
	else if(@{sv_match}[5]) {
		w_object = this.blankNode(@{ue_iri(sv_match+'[5]', b_unescape)});
	}
	// object term type is literal
	else {
		// contents
		w_object = this.literal(@{sv_match}[6], @{b_unescape});

		// set datatype if present
		if(@{sv_match}[7]) {
			w_object.datatype = this.namedNode(@{ue_iri(sv_match+'[7]', b_unescape)});
		}
		// otherwise, set language tag if present
		else if(@{sv_match}[8]) {
			let s_language = w_object.language = @{sv_match}[8].toLowerCase();
			if(this.validate && !RT_LANGUAGE_VALID.test(s_language)) return this._error(`invalid literal language tag: ${s_language}`);
			w_object.datatype = KT_RDFS_LANG_STRING;
		}
	}

	// emit data event
	fk_data(
		factory.quad(
			@{sv_match}[2]
				? this.blankNode(@{sv_match}[2])
				: this.namedNode(@{ue_iri(sv_match+'[1]', b_unescape)}),
			this.namedNode(@{ue_iri(sv_match+'[3]', b_unescape)}),
			w_object,
			@- QUADS
				@{sv_match}[9]
					? this.namedNode(@{ue_iri(sv_match+'[9]', b_unescape)})
					: (@{sv_match}[10]
						? this.blankNode(@{sv_match}[10])
						: ('string' === typeof @{sv_match}[9]
							? this.namedNode(@{ue_iri(sv_match+'[9]', b_unescape)})
							: KT_DEFAULT_GRAPH))
			@:
				@//@
				KT_DEFAULT_GRAPH
			@;
			@//@arguments
		)
		@//@arguments
	);

	// comments
	if(this.emit_comments) {
		this.emit_comments(@{sv_match}[@{QUADS? 11: 9}]);
	}
@;



@> parse_n({
	local: b_local=false,
}={})
	// match triples/quads
	for(;;) {
		@{if_match(STATEMENT_REGEX+'_ESCAPELESS_SP', 'm_statement_e_sp', true)}
			@{match_body('m_statement_e_sp')}
			
		@{else_if_match(STATEMENT_REGEX, 'm_statement', true)}
			@{match_body('m_statement', true)}

		@{else_retry()}
	} // end of while

	// update unparsed data string
	@{b_local? 's': 'this.s'} = s.substr(i);
@;


class reader {
	constructor(g_config) {
		let {
			// input medium
			input: g_input=null,

			// validate iris
			validate: b_validate=false,

			// debug
			debug: b_debug=false,
		} = g_config;

		// fields
		Object.assign(this, {
			// string buffer, accept left-over string from previous data chunk
			s: g_config.prepend || '',

			// string buffer length
			n: 0,

			debug: b_debug,

			validate: b_validate,

			destroyed: false,
		});

		// clean regex
		let r_clean = R_CLEAN;

		// validation
		Object.assign(this, b_validate
			? {
				namedNode(s_iri) {
					if(!RT_ABSOLUTE_IRI_VALID.test(s_iri)) return this._error(`invalid absolute IRI: "${s_iri}"`);
					return factory.namedNode(s_iri);
				},

				blankNode(s_label) {
					if(!RT_BLANK_NODE_LABEL_VALID.test(s_label)) return this._error(`invalid blank node label: "${s_label}"`);
					return factory.blankNode(s_label);
				},

				literal(s_literal, b_unescape=false) {
					if(!RT_LITERAL_CONTENTS_VALID.test(s_literal)) return this._error(`invalid literal: "${s_literal}"`);
					try {
						return factory.literal(b_unescape? @{unescape_literal('s_literal')}: s_literal);
					}
					catch(e_parse) {
						return this._error(`invalid string literal: "${s_literal}"`);
					}
				},
			}
			: {
				namedNode: factory.namedNode,

				blankNode: factory.blankNode,

				literal: (s_literal, b_unescape) => factory.literal(b_unescape? @{unescape_literal('s_literal')}: s_literal),
			});

		// transform stream
		let ds_transform;

		// whether or not data has been received before
		let b_init = false;

		// create transform
		ds_transform = this.transform = new stream.Transform({
			// do not decode strings into buffers
			decodeStrings: false,

			// output quad objects on readable side
			readableObjectMode: true,

			// once there's no more data to consume, invoke eof
			flush: (fk_flush) => {
				// there is still unparsed data
				if(this.s.length) {
					// append newline to end so we can match token
					this.s += '\n';

					// parse safely
					try {
						this.safe_parse();
					}
					// read error occurred; pass to flush errback and exit method
					catch(e_read) {
						return ds_transform.destroy(e_read);
					}

					// still unparsed characters; pass to flush errback and exit method
					if(this.s.length) {
						return ds_transform.destroy(new Error(`parsing error occurred in state: statement\n  ${this.s.substr(0, 50)}\n  ^ starting here`));
					}
				}

				// make buffer's alloc eligible for gc
				this.s = null;

				// final progress update: no additional bytes were read
				ds_transform.emit('progress', 0);

				// call end event listener
				ds_transform.emit('eof');

				// done flushing, close read stream
				fk_flush();
			},

			// on data event
			transform: (s_chunk, s_encoding, fk_chunk) => {
				// first transform
				if(!b_init) {
					// notify that data will begin
					ds_transform.emit('ready');

					// do not emit 'ready' event again
					b_init = false;
				}

				// concatenate current chunk to previous chunk
				let s = this.s += s_chunk;

				// remove whitespace & comments from beginning
				r_clean.lastIndex = 0;
				let m_clean = r_clean.exec(s);
				if(this.emit_comments) {
					this.emit_comments(m_clean[1]);
				}

				// update index and prepare to match statement
				this.i = r_clean.lastIndex;

				// cache chunk length
				this.n = s.length;

				// resume parsing
				try {
					this.safe_parse(true);
				}
				// read error occurred; emit and destroy stream
				catch(e_read) {
					return ds_transform.destroy(e_read);
				}

				// emit progress event updates
				ds_transform.emit('progress', s_chunk.length);

				// done transforming this chunk
				fk_chunk();
			},
		});
		
		// intercept pipe
		ds_transform.pipe = function(ds_out) {
			// non-object mode
			if(!ds_out._writableState.objectMode) {
				ds_out = stream.quads_to_json(ds_out);
			}

			// forward to super
			return Object.getPrototypeOf(this).pipe.apply(this, [ds_out]);
		};

		// when the writable side is piped into
		ds_transform.on('pipe', (ds_input) => {
			// input stream has encoding option; ensure stream encoding is utf8
			if('function' === typeof ds_input.setEncoding) {
				ds_input.setEncoding('utf8');
			}
		});

		// data event
		this.data = g_quad => ds_transform.push(g_quad);

		// new listener added
		ds_transform.on('newListener', (s_event) => {
			// comment
			if('comment' === s_event) {
				r_clean = R_CLEAN_COMMENTS;
				this.emit_comments = (s_captured) => {
					let a_comments = s_captured.slice(1).replace(/\n\s+$/, '').split(/\n+\s*#/g);

					for(let s_comment of a_comments) {
						ds_transform.emit('comment', s_comment);
					}
				};
			}
		});

		// bind events to transform stream
		this.bind(g_config);

		// input given
		if(g_input) {
			// input is stream
			if(g_input.stream) {
				let ds_input = g_input.stream;

				// go async so caller has chance to bind event listeners
				setTimeout(() => {
					ds_input.pipe(ds_transform);
				}, 0);
			}
			// string
			else if('string' === typeof g_input.string) {
				let s_input = g_input.string;

				// go async so caller has chance to bind event listeners
				setTimeout(() => {
					ds_transform.end(s_input, 'utf8');
				}, 0);
			}
			// invalid arg
			else {
				throw new TypeError(`Invalid argument for input parameter: ${'object' === typeof g_input? JSON.stringify(g_input): g_input}`);
			}
		}
	}

	_error(s_message) {
		this.destroyed = true;
		throw new Error(s_message);
	}


@$ H_PARSE_EVENTS = {
	error: {},
	comment: {},
	read: {once:true},
	progress: {},
	eof: {once:true},
	end: {}, // {once:true},
	data: {},  // attach data listener last
};

	bind(g_config) {
		let ds_transform = this.transform;
		@*{
			for(let [s_event, g_event] of Object.entries(H_PARSE_EVENTS)) {
				yield /* syntax: js */ `
					if(g_config.${s_event}) ds_transform.${g_event.once? 'once': 'on'}('${s_event}', g_config.${s_event});
					`.trim()+'\n';
			}
		}
	}

	safe_parse() {
		let s = this.s;
		let n = this.n;
		let i = this.i;
		let fk_data = this.data;

		@// parse chunk
		@{parse_n()};
	}
}


module.exports = function(...a_args) {
	let g_config = {};

	@{normalize_reader_config('g_config')}

	// create reader, return transform stream
	return (new reader(g_config)).transform;
};
